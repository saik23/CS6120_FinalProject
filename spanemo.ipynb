{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CS6120 Final Project: Group-14: Label-Correlation Aware Emotion Classification\n- In this project we studied the importance of using label-correlation idea in the task of emotion classification using tweets from SemEval dataset.\n- We perform the following tasks for this project:\n    - clean and preprocess the data,\n    - do some exploroatory analysis on the dataset,\n    - prepare and train the model with various loss functions,\n    - do ablation experiments with loss functions,\n    - and draw observations from the results.","metadata":{}},{"cell_type":"markdown","source":"### Environment setup\n\nBefore beginning the experiments, we do the required environment setup by installing all the required packages for the project","metadata":{}},{"cell_type":"code","source":"# package installs\n!pip install numpy\n!pip install sklearn\n!pip install fastprogress==0.2.3\n!pip install docopt==0.6.2\n!pip install transformers==3.0.2\n!pip install pandas==0.24.2\n!pip install ekphrasis\n!pip install tqdm==4.31.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset exploration\nIn this section, we do the following analysis on the dataset:\n- Identify the emotion distribution across the dataset (train, validation, and test splits.)\n- Identify the label correlation among train and validaiton splits.","metadata":{}},{"cell_type":"code","source":"# Dataset exploration\n# imports\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\n# Change the filenames accordingly to use the train validaiton and test files respectively\ntrain_filename = '/kaggle/input/semeval2018/2018-E-c-En-train/2018-E-c-En-train.txt'\nval_filename = '/kaggle/input/semeval2018/2018-E-c-En-dev/2018-E-c-En-dev.txt'\ntest_filename = '/kaggle/input/semeval2018/2018-E-c-En-test-gold.txt'\n\n# Read the data from the files to appropriate data frames.\ntrain_df = pd.read_csv(train_filename, sep='\\t')\nx_train, y_train = train_df.Tweet.values, train_df.iloc[:, 2:].values\n\nval_df = pd.read_csv(val_filename, sep='\\t')\nx_val, y_val = val_df.Tweet.values, val_df.iloc[:, 2:].values\n\ntest_df = pd.read_csv(test_filename, sep='\\t')\nx_test, y_test = test_df.Tweet.values, test_df.iloc[:, 2:].values\n\n# Concatenate all the label data\ny_cat = np.concatenate((y_train, y_val, y_test), axis=0)\n\n# count the number of emotions in each tweet. 0-neutral, 1-single emotion, 2-2 emotions ...\ncounts = np.zeros((11)) # 11 emotions possible at max\nfor y in y_cat:\n    num_emotions = np.count_nonzero(y)\n    counts[num_emotions]+=1\n\n# Original counts as is.\nprint(\"Emotion distribution counts:\", counts)\n\n# Percentage counts\nprint(\"Emotion distribution percentages:\", counts/109.83)\n\n# Label correlation on validation set labels.\ny_val_df = val_df.iloc[:, 2:]\ncorr_df = y_val_df.corr(method='kendall')\nsns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.heatmap(corr_df, annot=False)\n\n# Label correlation on the train set labels to be used for the Label Correlation Loss in later sections of the code.\ny_train_df = train_df.iloc[:, 2:]\nlabel_graph = train_df.corr(method='kendall')\nlabel_graph = label_graph.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T01:55:10.161414Z","iopub.execute_input":"2022-12-12T01:55:10.161795Z","iopub.status.idle":"2022-12-12T01:55:11.463136Z","shell.execute_reply.started":"2022-12-12T01:55:10.161761Z","shell.execute_reply":"2022-12-12T01:55:11.462180Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Emotion distribution counts: [ 293. 1481. 4491. 3459. 1073.  170.   16.    0.    0.    0.    0.]\nEmotion distribution percentages: [ 2.66775926 13.48447601 40.89046709 31.49412729  9.769644    1.54784667\n  0.14567969  0.          0.          0.          0.        ]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 842.4x595.44 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAr4AAAIeCAYAAABdmwybAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABdZklEQVR4nO3dd3hUdfr//9dkIJQUFYQIGiTiGpoURcoiRQQBAUMAiYLAooAiXVGqVEUpFoqA4C6gKEQgEBJB/CgqywpBlAWk7SIJJFQlQgohZWZ+f/BjvmSDEjIZzhzO83Fdc23mzMmZ18xicuee+7yPzeVyuQQAAADc5PyMDgAAAADcCBS+AAAAsAQKXwAAAFgChS8AAAAsgcIXAAAAlkDhCwAAAEug8AUAAMANMX36dLVq1Urh4eH6z3/+c9V9HA6HJk+erNatW6tNmzZatWpVsT0/hS8AAABuiEcffVSffPKJ7rzzzj/cJy4uTseOHdOXX36p6OhozZ07VykpKcXy/CWK5SgAAACwrLS0NKWlpRXYHhwcrODgYPf9Bg0aXPNYGzZs0JNPPik/Pz+VK1dOrVu31hdffKF+/fp5nJPCt5jk/nbE6Ageeb7Bq0ZHKLL3J99rdASPvDMh2egIRTb51HdGR/BI0wo1jI5QZD+nHzM6gkemBT1kdIQiq5zrMDqCR7aVsRkdociSlW10hCJblrTG6AherVWWrfhc8+bNK7B98ODBGjJkyHUd6+TJk6pcubL7fqVKlXTq1CmPM0oUvgAAAPBQnz59FBkZWWD7ld1eX0DhCwAAYAVO731a8b8jDZ6oVKmSTpw4oTp16kgq2AH2BCe3AQAAwGe0a9dOq1atktPpVGpqqr766iu1bdu2WI5N4QsAAGAFLqf3boX0+uuvq3nz5jp16pT69u2rDh06SJL69++vvXv3SpIiIiJ011136bHHHlP37t01aNAghYaGFstbwKgDAAAAbojx48dr/PjxBbYvXrzY/bXdbtfkyZO98vwUvgAAAFbgLHxn9mZF4QsAAGABrusYSbhZMeMLAAAAS6DjCwAAYAWMOtDxBQAAgDXQ8QUAALACZnzp+AIAAMAa6PgCAABYgRcvWWwWFL4AAABWwKgDow4AAACwBjq+AAAAVsByZnR8AQAAYA10fK/B4XDIbrcbHQMAAMAjXLLYRIXvyy+/rMTEROXm5qpKlSqaNm2aDh48qGnTpqlu3bratWuXbDab3n33XVWrVk2S9O6772rDhg269dZb1bBhQ23btk0xMTGSpLVr1+rTTz+Vw+FQYGCgJk2apHvuuUcxMTFav369AgICdPToUc2cOVM1atQw8qUDAACgGJhm1GHcuHGKiYlRXFyc7r33Xi1evFiSdPjwYT311FOKi4tT+/btNX/+fEnS5s2b9c033yg2NlbR0dE6evSo+1g7d+7Uxo0b9cknnygmJkbPPfecxo4d63589+7dGjVqlOLj4yl6AQDAzcHp9N7NJEzT8Y2NjVVcXJxyc3N14cIFVa1aVc2aNVNYWJhq1qwpSapXr56++eYbSVJCQoLat2+vsmXLSpI6d+6cryg+ePCgnnzySUmSy+VSWlqa+7keeOABValS5Ua+PAAAAO9i1MEche/OnTu1YsUKrVy5UuXKlVNcXJw+++wzSZK/v797Pz8/P+Xl5V3zeC6XS127dtWwYcOu+nhAQEDxBAcAAIDPMMWoQ1pamgIDA3XrrbcqJydHa9asueb3NGzYUJs2bVJWVpacTqfWr1/vfqxVq1aKjY3VqVOnJF06ge3nn3/2Wn4AAADDOR3eu5mEKTq+zZo10/r169W2bVvddtttatCggfbu3fun3/Poo49q165deuKJJ3TLLbeoXr16On/+vCTpoYce0vDhwzVw4EA5HA7l5uaqXbt2ql279o14OQAAADCAzeVyuYwO4S0ZGRkKDAyU0+nUuHHjVLFiRY0YMcIrz5X72xGvHPdGeb7Bq0ZHKLL3J99rdASPvDMh2egIRTb51HdGR/BI0wrmPXn15/RjRkfwyLSgh4yOUGSVc83T3bqabWVsRkcosmRlGx2hyJYlXfvTam/LPvCN145dqsYjXjt2cTJFx7eoRo0apePHj+vixYuqVauW+vfvb3QkAAAAGOSmLnzff/99oyMAAAD4BhMtO+YtN3XhCwAAgP8fy5mZY1UHAAAAwFN0fAEAAKyAUQc6vgAAALAGOr4AAAAW4HKZeym+4kDHFwAAAJZAxxcAAMAKWNWBwhcAAMASOLmNUQcAAABYAx1fAAAAK2DUgY4vAAAArIGOLwAAgBU4Wc6Mji8AAAAsgY5vMXm+watGR/DIBztnGB2hyAY0eMXoCB65w1bK6AhFtqR8S6MjeORACfPOu40sfbvRETyyzcTv/U8lzN0165Rl3p5Xul9poyOYGzO+FL4AAACWwHJmjDoAAADAGuj4AgAAWAGjDnR8AQAAYA10fAEAAKyAGV86vgAAALAGOr4AAABWQMeXwhcAAMAKXC5zr0FdHBh1AAAAgCXQ8QUAALACRh3o+AIAAMAa6PgCAABYARewoOMLAAAAa6DjCwAAYAXM+FL4AgAAWIKPjDokJiZq9OjROnfunG699VZNnz5dVatWzbfP2bNnNWbMGJ08eVJ5eXlq1KiRxo8frxIlPCtdGXUAAADADTNx4kT16NFDmzZtUo8ePTRhwoQC+yxcuFDVqlVTXFyc1q9fr3379unLL7/0+Lm9UvimpKQoOjo637b+/fvr2LFjf/p9s2fP1oYNGzx67piYGCUmJrrvf/3115o+fbpHxwQAADA9p9Nrt7S0NKWkpBS4paWl5Ytw9uxZ7d+/Xx07dpQkdezYUfv371dqamq+/Ww2mzIzM+V0OpWTk6Pc3FyFhIR4/BZ4ZdTh+PHjio6OVlRUlHvb4sWLr/l9w4YN8/i5165dq9tuu01hYWGSpEcffVSPPvqox8cFAADA1S1btkzz5s0rsH3w4MEaMmSI+/7JkycVEhIiu90uSbLb7apYsaJOnjypcuXKufd78cUXNWTIED388MPKyspSz5499eCDD3qcs1CF78svv6zExETl5uaqSpUqmjZtmg4ePKhp06apbt262rVrl2w2m959911Vq1ZNU6ZMUUpKiiIiInT33Xdrzpw5atWqlRYuXKj77rtPp0+f1uuvv66kpCRJl6r9559/XqNHj1bt2rX1zDPPaO7cuTp8+LB+//13nTlzRn/5y180bdo0BQUFadu2bXrvvfeUnZ0th8OhF154QR06dNCaNWv0888/6/XXX9d7772nUaNG6dSpU/r22281Z84cSdKiRYu0fv16SdL999+v8ePHKyAgQHPnzlViYqLS09OVnJysKlWqaPbs2SpTpozHbzIAAIDhvDjj26dPH0VGRhbYHhwcXKTjffHFFwoPD9eyZcuUmZmp/v3764svvlC7du08ylmoUYdx48YpJiZGcXFxuvfee93d28OHD+upp55SXFyc2rdvr/nz50uSJkyYoGrVqik2NtZdcF5p5MiRqlu3ruLi4hQXF6cnn3zyqs/7448/6p133tEXX3yhwMBA9/Fr1qypTz/9VOvWrdOSJUs0ffp0nT9/Xl27dlXt2rU1fvx4xcbG6q9//Wu+43333Xdav369Vq5cqbi4ODkcDvcxJennn3/W22+/rY0bNyovL09xcXGFeXsAAAAsLTg4WHfddVeB2/8WvpUqVdLp06flcDgkSQ6HQ2fOnFGlSpXy7bd8+XI98cQT8vPzU1BQkFq1aqWEhASPcxaq8I2NjVWXLl3UqVMnxcfH68CBA5KksLAw1axZU5JUr149JScnX/NYmZmZ2rVrl/72t7+5t13Z2r5Sy5Ytdfvtt0uSunXrpu3bt0uSUlNTNXToUHXs2FHPPfeczp8/n2+u949s27ZNjz/+uAIDA2Wz2dS9e3dt27bN/fjDDz+s4OBg2Ww21alT55ozyQAAAKbhxRnfwipfvrxq1Kih+Ph4SVJ8fLxq1KhRoBa86667tGXLFklSTk6Otm3bpr/85S8evwXXLHx37typFStW6MMPP1RcXJyGDx+unJwcSZK/v///O5Cfn/Ly8jwOVBiTJk1Sw4YNFRcXp9jYWN1xxx3Kzs72+LilSpVyf223291/jQAAAJieDxS+0qU6bvny5Wrbtq2WL1+uyZMnS7q0EMLevXslSWPHjtWPP/6oTp06qXPnzqpataq6d+/u8VtwzRnftLQ0BQYG6tZbb1VOTo7WrFlzzYMGBgYqIyPjqo8FBASofv36Wrp0qfr16yfpUgf3al3fb7/91v1YTEyMGjduLElKT0/XnXfeKZvNpn/96186evRovuOnp6df9bmbNGmiWbNmqXfv3goICNDq1asLjEMAAADAe6pVq6ZVq1YV2H7lQghVqlTRkiVLiv25r9nxbdasmapUqaK2bdvqmWeecY82/Jnw8HCFhYWpY8eOGjp0aIHHZ82apZ9++kkdO3bUE088odWrV1/1OA0aNNCIESPUrl07nT9/Xi+++KKkSyfbzZgxQxEREdq4caPCw8Pd3xMVFaX3339fERER+v777/Mdr0WLFurUqZOeeuopderUSZI0cODAa74eAAAA03M5vXczCZvL5XIZHeJq5s6dqwsXLmjUqFFGRymUZ6t2MzqCRz7YOcPoCEU2oMErRkfwyB0qde2dfFTtHHNfA+eAv3l+WP+vJlk++aO70LaVsRkdocjO6saM9XlLpyzz/neb7mc3OkKRRZ38xOgIyop/x2vHLtPxJa8duzhxyWIAAAAruM5Z3JuRzxa+Vy52DAAAAHjKZwtfAAAAFCMTzeJ6C4UvAACAFTDqULgLWAAAAABmR8cXAADAChh1oOMLAAAAa6DjCwAAYAXM+NLxBQAAgDXQ8QUAALACOr50fAEAAGANdHwBAACswOUyOoHhKHwBAACsgFEHRh0AAABgDXR8AQAArICOL4VvcXl/8r1GR/DIgAavGB2hyBbtnGl0BI8srD/B6AhF1ue3b4yO4JEmFaobHaHI3ks/YnQEj0SrsdERiizYZu7iIb6M3egIRXbclWV0hCKLMjoAJFH4AgAAWAOXLGbGFwAAANZAxxcAAMAKmPGl8AUAALAE1vFl1AEAAADWQMcXAADAChh1oOMLAAAAa6DjCwAAYAV0fOn4AgAAwBro+AIAAFgBF7Cg8AUAALACl5PlzBh1AAAAgCXQ8QUAALACTm6j4wsAAABroOMLAABgBZzc5rsd3/DwcGVmZioiIkIXL168Yc+bkJCgrVu33rDnAwAAwI3h8x3f2NjYG/p8O3bs0IULF/Twww/f0OcFAADwKlZ18J3C98svv9Q777yjUqVK6bHHHnNvDw8P108//aQyZcpoypQp2r59u/z9/VW2bFmtXLlSkrR8+XJ99NFHCgoKUosWLfTJJ58oISFBCQkJmj59umJiYiQp3/0jR45ozJgxysrKktPpVGRkpB5++GGtXLlSTqdT33//vTp06KABAwYY8n4AAAAUK05u843C97ffftNrr72mFStW6J577tHixYsL7HPw4EElJCRow4YN8vPz0/nz593bP/jgA8XGxqpcuXJ6/fXXC/Wcn376qVq1aqXnn39eknT+/Hndcssteuqpp3ThwgWNGjWq+F4gAAAADOcTM767d+9WzZo1dc8990iSoqKiCuwTGhqqvLw8jRs3TuvWrXNv37Fjh1q0aKFy5cpJkrp161ao53zooYe0atUqvffee9q2bZuCg4M9fyEAAAC+yun03s0kfKLwLYygoCB9/vnnevzxx3Xo0CF16NBBv/76659+j91ul8v1/+ZZsrOz3V+3bdtWn3zyiapUqaLFixfrlVde8Vp2AAAAGM8nCt969epp//79SkpKkiStWrWqwD6pqanKyspSs2bNNHLkSAUFBSk5OVkNGzbUli1blJqaKklau3at+3tCQ0OVnJys8+fPy+Vy6fPPP3c/dvToUVWoUEFdunTRoEGDtHfvXklSYGCg0tPTvfhqAQAADOByee9mEj4x41u+fHlNnTpVL7zwgkqXLp3v5LbLTp48qddee015eXlyOBxq3ry56tWrJz8/P/Xr109PPfWUAgMD1bhxYwUFBUmSQkJC1LdvX3Xp0kW33367HnroIf33v/+VJG3cuFFxcXEqWbKkbDabxo4dK0lq3bq11q1bp4iICE5uAwAAuInYXC4Tlel/ICMjQ4GBgZKkuXPn6ujRo5o1a9YNzZC1bPQNfb7i9uLE/xodocgW7ZxpdASPLKw/wegIRTbi9DdGR/BIkwrVjY5QZLt+P2J0BI9EBzU2OkKRBdtyjY7gkfjSJY2OUGTHXdnX3slHLT8aY3QEXXinv9eOXfalggsT+CKf6Ph66u2339ZPP/2k3NxchYaGasqUKUZHAgAA8C2s43tzFL4TJ040OgIAAAB83E1R+AIAAOAaXOZZdsxbfGJVBwAAAMDb6PgCAABYATO+dHwBAABgDXR8AQAALMBloksLewuFLwAAgBX4yKhDYmKiRo8erXPnzunWW2/V9OnTVbVq1QL7bdiwQQsWLJDL5ZLNZtOSJUt0++23e/TcFL4AAAC4YSZOnKgePXooIiJCsbGxmjBhgj766KN8++zdu1fz5s3TsmXLVKFCBaWnp8vf39/j56bwBQAAsAIvLmeWlpamtLS0AtuDg4MVHBzsvn/27Fnt379fS5YskSR17NhRU6dOVWpqqsqVK+feb+nSpXr22WdVoUIFSVJQUFCx5KTwBQAAgEeWLVumefPmFdg+ePBgDRkyxH3/5MmTCgkJkd1ulyTZ7XZVrFhRJ0+ezFf4/vLLL7rrrrvUs2dPXbhwQW3atNHAgQNls9k8yknhCwAAYAVenPHt06ePIiMjC2y/stt7PRwOhw4dOqQlS5YoJydH/fr1U+XKldW5c2ePclL4AgAAwCP/O9LwRypVqqTTp0/L4XDIbrfL4XDozJkzqlSpUr79KleurHbt2snf31/+/v569NFHtWfPHo8LX9bxBQAAsAKn03u3Qipfvrxq1Kih+Ph4SVJ8fLxq1KiRb8xBujT7u3XrVrlcLuXm5mr79u2qXr26x28BhS8AAIAVOF3eu12HSZMmafny5Wrbtq2WL1+uyZMnS5L69++vvXv3SpI6dOig8uXL6/HHH1fnzp117733qlu3bh6/BYw6AAAA4IapVq2aVq1aVWD74sWL3V/7+flpzJgxGjNmTLE+N4VvMXlnQrLRETxyh62U0RGKbGH9CUZH8MgLu6YYHaHINtQfZHQEj1SyBxgdocjuqlDX6Age+TXPbnSEIjtoN292SfKTea/eFa4yRkcwNy8uZ2YWjDoAAADAEuj4AgAAWIGPXLLYSHR8AQAAYAl0fAEAACzAdR3Ljt2sKHwBAACsgFEHRh0AAABgDXR8AQAArICOLx1fAAAAWAMdXwAAACvgAhZ0fAEAAGANdHwBAACsgBlfCl8AAAArcFH4MuoAAAAAa6DjCwAAYAV0fOn4AgAAwBpuusL3q6++Uvv27dW5c2cdOXLE6DgAAAC+wen03s0kbrpRh5UrV2ro0KFq3759sRzP4XDIbrcXy7EAAABgnJuq8J02bZp+/PFHJSYm6tNPP9XIkSM1a9YsZWZmSpKGDh2qli1bKi8vT88//7x+//13ZWdnq06dOpo8ebL8/f0VExOj9evXKyAgQEePHtXMmTNVo0YNg18ZAACAh5jxvbkK37Fjx+rAgQN69tln9eCDD6p3795atGiRKlasqDNnzqhbt26Kj49XUFCQZs2apdtuu00ul0ujRo3SmjVr9PTTT0uSdu/erdjYWFWpUsXgVwQAAFBMKHxvrsL3Srt27VJKSor69+/v3maz2XT06FHVrFlT//jHP7RlyxY5nU6dP39epUuXdu/3wAMPUPQCAADcZG7awtflcik8PFyffPJJgcfWrVunH3/8UZ988okCAwO1cOFCJSUluR8PCAi4gUkBAAC8z+Wi43vTrepwWf369XX06FFt377dvW3Pnj1yuVxKT0/XbbfdpsDAQKWnpys+Pt7ApAAAALgRbtqO7y233KL58+dr5syZmjZtmnJzcxUaGqqFCxeqc+fO+vrrr9WuXTuVL19eDz74oLKzs42ODAAA4D3M+N58he/HH3/s/rpOnTr57l8WFBSkpUuXXvX7u3Tpoi5dungrHgAAAAxy0xW+AAAAuAo6vjfvjC8AAABwJTq+AAAAFuCi40vhCwAAYAkUvow6AAAAwBro+AIAAFiB0+gAxqPjCwAAAEug4wsAAGABnNxGxxcAAAAWQccXAADACuj4UvgCAABYAie3MeoAAAAAa6DjCwAAYAGc3EbHFwAAABZBxxcAAMAKmPGl4wsAAABroONbTCaf+s7oCB5ZUr6l0RGKrM9v3xgdwSMb6g8yOkKRrd/1vtERPHLu6b5GRyiyso1DjI7gkaeWnTM6QpElZv9mdASPDCl5r9ERiuyOPFqWnmDGl8IXAADAGvi7gVEHAAAAWAMdXwAAAAtw0fGl4wsAAABroOMLAABgBXR86fgCAADAGuj4AgAAWAAzvhS+AAAA1kDhy6gDAAAAbpzExERFRUWpbdu2ioqKUlJS0h/ue+TIEdWtW1fTp08vluem8AUAALAAl9N7t+sxceJE9ejRQ5s2bVKPHj00YcKEq+7ncDg0ceJEtW7duhhe/SWMOgAAAMAjaWlpSktLK7A9ODhYwcHB7vtnz57V/v37tWTJEklSx44dNXXqVKWmpqpcuXL5vnfRokVq2bKlLly4oAsXLhRLTgpfAAAAC/DmyW3Lli3TvHnzCmwfPHiwhgwZ4r5/8uRJhYSEyG63S5LsdrsqVqyokydP5it8Dx48qK1bt+qjjz7S/Pnziy0nhS8AAAA80qdPH0VGRhbYfmW3t7Byc3P12muv6c0333QXyMWFwhcAAMACvNnx/d+Rhj9SqVIlnT59Wg6HQ3a7XQ6HQ2fOnFGlSpXc+/z66686duyYBgwYIOnSGIXL5VJGRoamTp3qUU4KXwAAACtw2YxOoPLly6tGjRqKj49XRESE4uPjVaNGjXxjDpUrV1ZCQoL7/ty5c3XhwgWNGjXK4+e3zKoOERERunjxotExAAAALG3SpElavny52rZtq+XLl2vy5MmSpP79+2vv3r1efW7LdHxjY2ONjgAAAGAYX7lyW7Vq1bRq1aoC2xcvXnzV/a88Oc5Tlun4hoeHKzMzU3v27FFUVJQ6deqkqKgo7dmzR5I0efJkffjhh+799+/fr7Zt28rlchkVGQAAAMXIMoWvJLlcLg0dOlTDhw9XXFychg0bpqFDhyonJ0fPPPOMoqOj3YXu8uXL1aNHD9lsxs/DAAAAeMrltHntZhaWKnyPHz+ukiVLqkmTJpKkv/71rypZsqQSExNVrVo1hYaGasuWLTp//rw2b96sLl26GJwYAAAAxcUyM76F0atXL61YsUK//PKLHnvsMQUFBRkdCQAAoFj4yoyvkSzV8b3zzjuVm5ur7du3S5K2bdumvLw8hYWFSZJatGihxMRELVmyRD169DAyKgAAQLFyuWxeu5mFpTq+fn5+mjNnjt544w1duHBBZcuW1ezZs+Xv7+9+vHPnztqyZYuqV69ucFoAAAAUJ0sUvmfPnlWpUqVUpkwZ1alTR9HR0X+4744dO9S7d+8bmA4AAMD7GHWwwKjD/v371b17dw0aNOhPV2jYu3evWrduraCgILVt2/YGJgQAAMCNcNN3fGvWrKmvv/76mvvdf//9+uqrr25AIgAAgBvPTMuOectN3/EFAAAAJAt0fAEAACBxMVoKXwAAAEtg1IFRBwAAAFgEHV8AAAALoONLxxcAAAAWQccXAADAAji5jY4vAAAALIKOLwAAgAUw40vhCwAAYAkuF4Uvow4AAACwBDq+AAAAFuByGp3AeHR8AQAAYAl0fAEAACzAyYwvhW9xaVqhhtERPHKghHk//2hSobrRETxSyR5gdIQiO/d0X6MjeOTWFUuMjlBkR5sPNDqCR0L8goyOUGSlS4cYHcEjR2wOoyMUWTkHH1TDMxS+AAAAFsCqDhS+AAAAlsA6vpzcBgAAAIug4wsAAGABLpfRCYxHxxcAAACWQMcXAADAApjxpeMLAAAAi6DjCwAAYAFcwILCFwAAwBJYx5dRBwAAAFgEHV8AAAALYDkzOr4AAACwCDq+AAAAFsDJbXR8AQAAYBF0fAEAACyAVR1uoo5veHi4MjMzjY4BAAAAH0XHFwAAwAJY1eEm6vheac+ePYqKilKnTp0UFRWlPXv2SJLGjRunZcuWuff7z3/+o0cffVQul0sZGRkaN26cunXrpk6dOun111+Xw+Ew6iUAAAAUK6fL5rWbWdx0hW9OTo6GDh2q4cOHKy4uTsOGDdPQoUOVk5OjyMhIrVu3zr1vTEyMIiMjZbPZ9Oabb+qhhx7S6tWrFRsbq9TUVK1Zs8a4FwIAAIBiddONOiQmJqpkyZJq0qSJJOmvf/2rSpYsqcTERDVo0ECZmZk6dOiQqlWrpvj4eEVHR0uSNm/erD179mjJkiWSpIsXLyokJMSw1wEAAFCcOLntJix8r6Vz585au3atGjZsqGrVqunOO++UJLlcLs2fP1+hoaEGJwQAAIA33HSjDmFhYcrNzdX27dslSdu2bVNeXp7CwsIkXSp84+PjtWrVKnXp0sX9fa1atdKiRYvcc72pqalKTk6+8S8AAADAC5jxvQk7vv7+/pozZ47eeOMNXbhwQWXLltXs2bPl7+8vSapcubLuvfde7dixQ++88477+8aOHauZM2cqIiJCNptNJUuW1NixY+kAAwAA3CRumsL30KFD7q/r1Knjnt29mqVLlxbYFhgYqMmTJ3sjGgAAgOFYzewmKnwBAADwx8w0kuAtN92MLwAAAHA1dHwBAAAswFeWM0tMTNTo0aN17tw53XrrrZo+fbqqVq2ab5/3339fGzZskJ+fn0qWLKkRI0aoWbNmHj83hS8AAABumIkTJ6pHjx6KiIhQbGysJkyYoI8++ijfPnXq1NGzzz6rMmXK6ODBg3rmmWe0detWlS5d2qPnZtQBAADAApxevKWlpSklJaXALS0tLV+Gs2fPav/+/erYsaMkqWPHjtq/f79SU1Pz7desWTOVKVNGkhQeHi6Xy6Vz5855/B7Q8QUAAIBHli1bpnnz5hXYPnjwYA0ZMsR9/+TJkwoJCZHdbpck2e12VaxYUSdPnlS5cuWueux169apSpUquuOOOzzOSeELAABgAS55b8a3T58+ioyMLLA9ODjYo+Pu2LFDs2fP1j/+8Q+PjnMZhS8AAIAFOL24kG9wcHChitxKlSrp9OnTcjgcstvtcjgcOnPmjCpVqlRg3127dumVV17R/Pnzdc899xRLTmZ8AQAAcEOUL19eNWrUUHx8vCQpPj5eNWrUKDDmsGfPHo0YMUJz5sxRrVq1iu35KXwBAAAswCmb127XY9KkSVq+fLnatm2r5cuXu6+c279/f+3du1eSNHnyZF28eFETJkxQRESEIiIi8l2lt6gYdQAAAMANU61aNa1atarA9sWLF7u/XrNmjVeem8IXAADAArx5cptZMOoAAAAAS6DjCwAAYAFOowP4AApfAAAAC2DUgcK32PycfszoCB4ZWfp2oyMU2XvpR4yO4JG7KtQ1OkKRlW0cYnQEjxxtPtDoCEV295YFRkfwyLkHhxsdocjO5GUaHcEjje1BRkcosmol0o2OAJOj8AUAALAARh04uQ0AAAAWQccXAADAAuj40vEFAACARdDxBQAAsABWdaDwBQAAsAQndS+jDgAAALAGOr4AAAAW4GTUgY4vAAAArIGOLwAAgAW4jA7gA+j4AgAAwBLo+AIAAFgAF7Cg8AUAALAEp42T2xh1AAAAgCXQ8QUAALAATm6j4wsAAACL8KnCNyUlRdHR0fm29e/fX8eOHbvuY0VEROjixYvFFQ0AAMDUnF68mYVPFb7Hjx8vUPguXrxYVapUue5jxcbGqnTp0sUVDQAAACbn1RnfLVu26J133pHD4VC5cuU0ZcoUnTp1Sm+88YaqV6+uffv2qUyZMnrrrbd07733asqUKUpJSVFERITuvvtuzZkzR61atdLChQt13333qVevXqpVq5b27Nmj48ePq3fv3goJCdHy5ct15swZvfLKK2rfvr0kKTw8XD/99JPKlCmjKVOmaPv27fL391fZsmW1cuVKpaSkqGvXrurevbv++c9/6uLFi5o1a5ZWrlyp3bt3q3Tp0po/f74qVKjgzbcIAADghnCyqIP3Or5nz57Vq6++qlmzZikuLk4dO3bUyJEjJUmHDh1St27d9Pnnn6tnz5569dVXJUkTJkxQtWrVFBsbqzlz5lz1uKdOndLy5cv12Wefac6cOfrvf/+rlStX6r333tObb75ZYP+DBw8qISFBGzZs0Pr16/XBBx+4Hzt37pwefPBBrVu3Tt26ddPf/vY39ezZU3FxcapVq5aWL1/uhXcGAADgxnPK5rWbWXit8N29e7eqV6+ue++9V5LUtWtXHThwQJmZmbr77rvVsGFDSZdmcf/zn/8oIyOjUMdt166d/Pz8FBISoltvvVWtW7eWJNWqVUunT59WdnZ2vv1DQ0OVl5encePGad26dfkeK1u2rFq2bOn+/jvuuEM1atRw3y/KbDEAAAB8k0/N+BZGqVKl3F/b7Xb3fbvdLknKy8vLt39QUJA+//xzPf744zp06JA6dOigX3/9VZLk7+/v3s/Pzy/ffbvdLofD4bXXAQAAcCO5vHgzC68VvvXq1dPBgwf1yy+/SJLWrl2rmjVrKiAgQMeOHdPOnTslSXFxcbrvvvsUGBiowMDAQnd+Cys1NVVZWVlq1qyZRo4cqaCgICUnJxfrcwAAAMD3ee3ktnLlymnGjBkaOXKk8vLyVK5cOc2cOVOnTp3Sfffdp1WrVmnSpEkqXbq0ZsyYIenSCWlhYWHq2LGj7rnnnj+c870eJ0+e1Guvvaa8vDw5HA41b95c9erV04kTJzw+NgAAgFlwcptkc7lcN7RDnZCQoOnTpysmJuZGPq3XVbgl3OgIHlla+gGjIxRZVPp2oyN4pFOFukZHKLIPe/tfeycfdnLNeaMjFNndWxYYHcEjTz843OgIRXYmL9PoCB6JsFcyOkKRPeJKNzpCkT2QHGt0BH105zNeO3bv4+ZYEIBLFgMAAFiAmS404S03vPBt1KjRTdftBQAA8HVmOgnNW0y3qgMAAABQFIw6AAAAWAAnt9HxBQAAgEXQ8QUAALAATm6j4wsAAACLoOMLAABgAXR8KXwBAAAswcXJbYw6AAAAwBro+AIAAFgAow50fAEAAGARdHwBAAAsgI4vHV8AAABYBB1fAAAAC3AZHcAHUPgWk2lBDxkdwSPbSpj3A5BoNTY6gkd+zbMbHaHInlp2zugIHgnxCzI6QpGde3C40RE8suLH94yOUGQnHhtgdASPLDtr3vLnU7+yRkcosgeMDiDJyXJmjDoAAADAGuj4AgAAWIB5P9stPnR8AQAAYAkUvgAAABbg9OLteiQmJioqKkpt27ZVVFSUkpKSCuzjcDg0efJktW7dWm3atNGqVauu81mujsIXAAAAN8zEiRPVo0cPbdq0ST169NCECRMK7BMXF6djx47pyy+/VHR0tObOnauUlBSPn5vCFwAAwAJcXrylpaUpJSWlwC0tLS1fhrNnz2r//v3q2LGjJKljx47av3+/UlNT8+23YcMGPfnkk/Lz81O5cuXUunVrffHFFx6/B5zcBgAAAI8sW7ZM8+bNK7B98ODBGjJkiPv+yZMnFRISIrv90lKedrtdFStW1MmTJ1WuXLl8+1WuXNl9v1KlSjp16pTHOSl8AQAALMCb6/j26dNHkZGRBbYHBwd770mLgMIXAADAAry5nFlwcHChitxKlSrp9OnTcjgcstvtcjgcOnPmjCpVqlRgvxMnTqhOnTqSCnaAi4oZXwAAANwQ5cuXV40aNRQfHy9Jio+PV40aNfKNOUhSu3bttGrVKjmdTqWmpuqrr75S27ZtPX5+Cl8AAAAL8ObJbddj0qRJWr58udq2bavly5dr8uTJkqT+/ftr7969kqSIiAjdddddeuyxx9S9e3cNGjRIoaGhRX7tlzHqAAAAgBumWrVqV12Xd/Hixe6v7Xa7uyAuThS+AAAAFuC87t7szYdRBwAAAFgCHV8AAAAL8OaqDmZB4QsAAGABDDqYYNRh9uzZ2rBhw3V/37hx47Rz504vJAIAAIAZ+XzHd9iwYUX6vjfeeKOYkwAAAJgXow4eFr7h4eEaNGiQvv76a128eFEvvfSSe3Hh3bt3a9asWcrMzJQkDR06VC1bttTZs2f18ssv6+zZs5KkJk2aaOzYsfrpp580depUOZ1O5eXlaeDAgerYsaNGjx6t2rVr65lnntHcuXN15MgRZWRkKCkpSbVq1dKAAQP01ltv6cSJE2rTpo1GjRolSerVq5eeffZZPfLII4qOjtbSpUvl7+8vp9Op9957T9WqVVOrVq3UqVMnbd++XadPn3bnio+P1/nz5zVt2jQ99NBDnrxFAAAA8BEed3z9/PwUGxurI0eO6Omnn1aDBg1UsmRJTZw4UYsWLVLFihV15swZdevWTfHx8YqLi1OVKlW0dOlSSdL58+clXVq77bnnnlPHjh3lcrmUnp5+1efbt2+f1qxZo7JlyyoyMlJvv/22PvzwQ+Xl5enRRx9VVFSUqlatmu97ZsyYoY0bN6pixYrKycmRw+FwP5aTk6Po6Gjt2bNHvXv31iuvvKLVq1drw4YNeuedd7RixQpP3yIAAADDOW1GJzCex4Xvk08+KUm65557VLNmTf373/9WiRIllJKSov79+7v3s9lsOnr0qOrWraulS5dq+vTpatiwoR5++GFJUqNGjbRgwQIdO3ZMTZs2Vd26da/6fA8//LCCgoIkXeo4V69eXf7+/vL391dYWJiOHTtWoPBt3LixRo8erUceeUQtW7bMd+WPxx9/XJJUq1YtZWVlqX379pKk2rVr69ixY56+PQAAAPARXpnxdblcCg8P1yeffHLVx9euXavvv/9esbGxWrRokVasWKG//e1vatWqlb7//ntNnTpVTZs21YgRIwp8b6lSpdxf2+32Avev7OZeNm/ePO3du1fbt29X7969NWnSJLVo0SLf8ex2e777fn5+ysvLK+I7AAAA4Fu4gEUxFL5r1qzRiy++qKSkJO3fv1/16tVTiRIldPToUW3fvl2NGzeWJO3Zs0f333+/UlJSdMcdd6hDhw5q0KCB2rRpI6fTqaNHjyosLExVqlRR2bJltW7dOk+jSZLy8vJ04sQJ1alTR3Xq1NGxY8d04MABd+ELAABgBZS9xVD4OhwOde7cWVlZWZoyZYrKly8vSZo/f75mzpypadOmKTc3V6GhoVq4cKF27NihpUuXys/PT06nU5MnT5afn58+/vhjJSQkqGTJkvL399f48eM9fnGS5HQ6NXr0aKWnp8tms6lSpUp6+eWXi+XYAAAAMA+by+Uq8h8A4eHh+umnnxQQEFCcmUxp8V3PGB3BI0dLmHeRkyZZ5v4b9tcSdqMjFNka+zmjI3gkxK+00RGK7Jwrx+gIHlnx43tGRyiyE48NMDqCR5adDTE6QpGl2cz7u2pWkvEny4+p2sNrx34z6VOvHbs4+fwFLAAAAIDi4NGow6FDh4orBwAAALyIk9vo+AIAAMAifP6SxQAAAPAc/V4KXwAAAEsw76mBxYdRBwAAAFgCHV8AAAAL4OQ2Or4AAACwCDq+AAAAFkC/l44vAAAALIKOLwAAgAWwqgOFLwAAgCW4GHZg1AEAAADWQMcXAADAAhh1oOMLAAAAi6DjW0wq5zqMjuCRn0qYN3+wzdx/wx60242OUGSJ2b8ZHcEjpUuHGB2hyM7kZRodwSMnHhtgdIQiq/zlIqMjeCSzwTijIxRZpsz7u8oXcAELOr4AAACwCDq+AAAAFkC/l8IXAADAEhh1YNQBAAAAFkHHFwAAwALMfSp48aDjCwAAAEug4wsAAGABXLKYji8AAAAsgo4vAACABTDjS+ELAABgCYw6MOoAAAAAi6DjCwAAYAGMOtDxBQAAgEXQ8QUAALAAp4sZXzq+AAAAsAQ6vgAAABZAv9eEhe/cuXN14cIFjRo1yugoAAAApuGk9GXUAQAAANZwwzu+WVlZGjVqlA4fPqwSJUooLCxM48eP10svvaTMzExlZ2erRYsWevXVVyVJ6enpGjdunP7zn/+oQoUKuuOOO3T77bdLutT9TUxMVHp6upKTk1WlShXNnj1bZcqUUU5Ojt5991398MMPysnJUXh4uCZNmqSAgABFR0dr6dKl8vf3l9Pp1HvvvaewsDBNmTJF27dvl7+/v8qWLauVK1fe6LcHAADAK7iAhQGF79atW5WZmakNGzZIks6fP6/SpUtr4cKFCggIUG5urp577jlt2bJFzZs31/vvv6+AgAB98cUXSk1NVZcuXdS+fXv38X7++WetXr1aQUFBeu655xQXF6fu3bvrww8/VFBQkFavXi1JmjlzphYtWqQRI0ZoxowZ2rhxoypWrKicnBw5HA4dPHhQCQkJ2rBhg/z8/HT+/Pkb/dYAAADAi2544Vu9enX98ssvmjx5sho2bKiWLVvK4XBoxowZ2rVrl1wul3777TcdPHhQzZs3V0JCgsaPHy9JKleunNq0aZPveA8//LCCg4MlSXXq1NGxY8ckSZs3b1ZGRoY2bdokScrJyVH16tUlSY0bN9bo0aP1yCOPqGXLlgoNDVVoaKjy8vI0btw4NWrUSI888siNeksAAAC8jgtYGFD4hoaGKj4+Xtu3b9eWLVv07rvvKiIiQmlpaVq1apVKlSql1157TdnZ2YU6XqlSpdxf2+129/e5XC5NnDhRTZo0KfA98+bN0969e7V9+3b17t1bkyZNUosWLfT5558rISFB33//vWbNmqW1a9eqQoUKxfPCAQAA8KeysrI0ZswY7du3T3a7XaNGjbpqM/Krr77S/PnzlZOTI5fLpa5du+rZZ5+95vFv+Mltp06dkt1uV+vWrTVmzBilpqYqJSVFFSpUUKlSpXT69Gl9/fXX7v0bN26smJgYSdLvv/+ur776qlDP06pVKy1dulQXL16UJGVkZOiXX35RXl6ekpOTVadOHQ0YMEBNmzbVgQMHlJqaqqysLDVr1kwjR45UUFCQkpOTi/8NAAAAMIBTLq/disvf//53BQYG6v/+7/+0cOFCjR8/XpmZmQX2q1ChghYsWKD4+HitXLlSK1as0M6dO695/Bve8T106JDefvttSZLT6dSAAQPUoUMHDRs2TB07dlRISEi+Lu2LL76osWPHql27dqpQoYIaNGhQqOcZMGCA5s2bp27duslms8lms2nw4MEKDQ3V6NGjlZ6eLpvNpkqVKunll1/WiRMn9NprrykvL08Oh0PNmzdXvXr1vPEWAAAA3HDePLktLS1NaWlpBbYHBwe7R1ILY+PGjXrrrbckSVWrVlXt2rW1ZcuWfOd3SVLdunXdXwcFBalatWo6fvz4NetEm8vF9euKw+chTxsdwSPxZRxGRyiyHhfNPbW0w7+00RGKbEn2YaMjeKRG6RCjIxTZ6bwMoyN45OMQm9ERiqzyl4uMjuCR8Q3GGR2hyNJk3t9VC5I+MzqCut39hNeO3WJkG82bN6/A9sGDB2vIkCGFPk79+vX19ddfq1y5cpKkSZMm6e6771bfvn3/8Ht++eUX9ezZU7GxsQoJ+fOf66a7gAUAAACunzfbRH369FFkZGSB7f/b7Y2MjNSJEyeueozvv//+up/3zJkzevHFFzVx4sRrFr0ShS8AAAA8VNiRhrVr1/7p45UrV9bx48fdHd+TJ0+qUaNGV9337Nmz6tu3r/r161dgFOKPcOU2AAAAC3C5XF67FZd27dopOjpakpSUlKS9e/eqWbNmBfb7/fff1bdvX/Xs2VNPPvlkoY9P4QsAAACf8NxzzyktLU1t2rTR888/rylTpigwMFCSNHv2bK1YsUKStGjRIiUlJSk6OloRERGKiIjQmjVrrnl8Rh0AAAAsoDiXHfOWsmXLas6cOVd9bNiwYe6vR40apVGjRl338Sl8AQAALMDcayAVD0YdAAAAYAl0fAEAACzAmxewMAs6vgAAALAEOr4AAAAWYIaT27yNji8AAAAsgY4vAACABRTnhSbMio4vAAAALIGOLwAAgAWwji+FLwAAgCWwnBmFb7HZVsZmdASPdMoy79RLfBm70RE84mfiv8GHlLzX6AgeOWJzGB2hyBrbg4yO4JFlZ837CzizwTijI3jk9Z1vGB2hyD6qN8HoCDA5Cl8AAAALYDkzTm4DAACARdDxBQAAsACWM6PjCwAAAIug4wsAAGABzPhS+AIAAFgCy5kx6gAAAACLoOMLAABgAU5ObqPjCwAAAGug4wsAAGAB9Hvp+AIAAMAi6PgCAABYAMuZUfgCAABYAoUvow4AAACwCDq+AAAAFuBiOTNrdHxPnz6tXr16GR0DAAAABjJlx9fhcMhutxdq37y8PIWEhOjjjz/2cioAAADfxYyvQYVvVlaWRo0apcOHD6tEiRIKCwtTixYt9O2332rOnDmSpJiYGPf9mJgYrV+/XgEBATp69KhmzpypadOmqXr16tq1a5fOnz+v9u3b66WXXpIk9erVS9WrV9fu3bt1yy23aOLEieratasSEhKu+tyzZ8+WJK1du1affvqpHA6HAgMDNWnSJN1zzz1GvEUAAAAoZoYUvlu3blVmZqY2bNggSTp//ry+/vrrP/2e3bt3KzY2VlWqVHFv++WXX7Ry5UplZ2frqaeeUv369fXII49IkpKTk/Xpp5+qRIkSSklJ+dPnlqSdO3dq48aN+uSTT+Tv76/vvvtOY8eO1cqVK4v1tQMAABjBRcfXmMK3evXq+uWXXzR58mQ1bNhQLVu2vOb3PPDAA/mKXknq3LmzSpQooRIlSujxxx/X9u3b3YVvp06dVKJEwZf3R8+9efNmHTx4UE8++aSkSwPgaWlpnr1QAAAAH8HJbQad3BYaGqr4+Hg1bdpU27ZtU0REhOx2u5xOp3uf7OzsfN8TEBBwXc9RtmzZQj93dna2XC6XunbtqtjYWMXGxmr9+vX69ttvr/u1AQAAwDcZUvieOnVKdrtdrVu31pgxY5SamqrQ0FAdOnRIOTk5ysnJ0aZNm655nPXr1ysvL08XLlzQxo0b1bhx4yI997lz59SqVSvFxsbq1KlTki6dQPfzzz97/FoBAAB8gVMur93MwpBRh0OHDuntt9+WJDmdTg0YMEAPPPCAmjRpog4dOqhixYqqXr26fv311z89zj333KOnnnrKfXLb5TGH633ukJAQhYSEaPjw4Ro4cKAcDodyc3PVrl071a5d2/MXDAAAAMPZXCYd+OjVq5eeffbZQhW7N8L4qj2MjuCRv2Y5r72Tj/qujM3oCB7xk3nzV80z91LgR0o4jI5QZBWdhVvS0Vdl2kz5q0eSlGkz789LSXp95xtGRyiyj+pNMDpCkT2XstzoCKp/R1OvHXvXqX957djFydy/tQAAAIBCMuUFLCRxQQoAAIDrYKZZXG8xbeELAACAwmMdX0YdAAAAYBF0fAEAACzAac71DIoVHV8AAABYAh1fAAAAC2DGl44vAAAALIKOLwAAgAUw40vhCwAAYAmMOjDqAAAAAIug4wsAAGABjDrQ8QUAAIBF0PEFAACwAGZ86fgCAADAR2RlZWn48OFq06aN2rVrp2+++eZP98/OzlaHDh3UpUuXQh2fji8AAIAFmGHG9+9//7sCAwP1f//3f0pKSlLPnj315ZdfKiAg4Kr7v/vuu6pbt64OHjxYqONT+BaTZGUbHcEj6X6ljY5QZMddWUZH8Ei4yhgdocjuyHMaHcEj5Rzm/dCrWol0oyN45FO/skZHKLJMOYyO4JGP6k0wOkKR9f73FKMjmJoZRh02btyot956S5JUtWpV1a5dW1u2bFH79u0L7Ltz504lJSWpb9++FL4AAAC4MdLS0pSWllZge3BwsIKDgwt9nBMnTujOO+90369UqZJOnTpVYL8LFy5o2rRpWrBggZKSkgp9fApfAAAAC3C5vPcp3bJlyzRv3rwC2wcPHqwhQ4a470dGRurEiRNXPcb3339f6OebMWOGevTooZCQEApfAAAA3Dh9+vRRZGRkge3/2+1du3btnx6ncuXKOn78uMqVKydJOnnypBo1alRgvx9//FFbtmzR/PnzlZ2drfPnz6tTp06Ki4v70+NT+AIAAFiA04szvtc70vBH2rVrp+joaN1///1KSkrS3r179fbbbxfY78oCNyEhQdOnT1dMTMw1j2/eMzsAAABwU3nuueeUlpamNm3a6Pnnn9eUKVMUGBgoSZo9e7ZWrFjh0fHp+AIAAFiAywTLmZUtW1Zz5sy56mPDhg276vZGjRoVqtsrUfgCAABYgjdHHcyCUQcAAABYAh1fAAAACzDDqIO30fEFAACAJdDxBQAAsAAnHV86vgAAALAGOr4AAAAW4GJVBwpfAAAAK+DkNkYdAAAAYBGmL3znzp2rnJycYjvegQMHtGHDhmI7HgAAgC9wyuW1m1mYvvCdN2+ecnNzC2zPy8sr0vEOHDigL774wtNYAAAA8DGmnvGdPHmyJOmpp56Sn5+f7rzzTt12221KTExUZmam3n//fXXt2lUJCQmSpJSUFPf9s2fP6uWXX9bZs2clSU2aNNHAgQM1Z84cZWRkKCIiQg899JDGjx9v2OsDAAAoLsz4mrzwnThxoj799FOtXLlSAQEBGj16tA4cOKDly5erbNmySklJ+cPvjYuLU5UqVbR06VJJ0vnz53XLLbdo6NCh+vbbbzVnzpwb9CoAAABwI5h+1OF/tWvXTmXLlr3mfnXr1tWWLVs0ffp0ffPNN4X6HgAAALNyulxeu5nFTVf4XlnAlihRIl9bPzs72/11/fr1tXbtWtWuXVuxsbHq3bv3Dc0JAABwI7lcLq/dzML0hW9AQIAyMjKu+tjtt9+u3NxcHT16VJIUHx/vfiw5OVmBgYHq0KGDxowZo3379snpdCowMFDp6ek3JDsAAABuHFPP+ErSs88+q969e6t06dK688478z1WokQJjRs3Tn379lW5cuXUsmVL92M7duzQ0qVL5efnJ6fTqcmTJ8vPz09NmjTRP/7xDz3xxBNq2LAhJ7cBAICbgpmWHfMWm8tM/Wkf1qdqV6MjeOTx7NJGRyiyOP8soyN4JFxljI5QZHWyzf3jI8dmMzpCkVUrcfVPusziU7t5z6vIlMPoCB5pkOdvdIQi6/3vKUZHKLKSt99jdATdEljNa8c+n/GL145dnEzf8QUAAMC10eu8CWZ8AQAAgMKg4wsAAGABZlp2zFvo+AIAAMAS6PgCAABYgItVHSh8AQAArIBRB0YdAAAAYBF0fAEAACyA5czo+AIAAMAi6PgCAABYACe30fEFAACARdDxBQAAsABmfCl8AQAALIHCl1EHAAAAWAQdXwAAAAug30vHFwAAABZhczHwAQAAAAug4wsAAABLoPAFAACAJVD4AgAAwBIofAEAAGAJFL4AAACwBApfAAAAWAKFLwAAACyBwhcAAACWQOELAAAAS6DwBQAAgCVQ+AIAAMASKHx9lNPp1MGDB42OYVmLFy8u1DZfY/Z/N+3atdPy5cuVkZFhdBTAEGfPntW///1vo2NYxhtvvFGobbh52Fwul8voELi6Tp06KS4uzugYRZKdna3169crOTlZeXl57u2vvvqqgakKLzIyUmvXrr3mNl9k5n83+/fv1yeffKJvvvlGbdq0Uc+ePXXfffcZHavQXC6XVq9eraSkJL3yyitKSUnRmTNn9MADDxgd7ZrOnj2r5cuX69ixY/n+m509e7aBqQpv586deuedd3Ts2DE5HA65XC7ZbDZt27bN6GjX1KNHD33wwQdyuVzq0KGDgoOD1bx5c40aNcroaIWSlJSkMWPG6PTp09q8ebP27dunzZs3a8iQIUZHu6ar/Vzv3Lmz1q1bZ0wgeF0JowPgj919991KSUnRXXfdZXSU6zZs2DDl5uaqTp068vf3NzpOof3rX//S1q1bdebMGc2YMcO9PSMjQ2b5G9HM/25q1qypN954Q2lpaVqzZo369++vu+66S3369NFjjz1mdLxrevPNN3X27Fnt27dPr7zyigICAjRt2jStXr3a6GjX9OKLL6pmzZpq0qSJ7Ha70XGu27hx4zR8+HDVrl1bfn7m+jDzwoULCgoKUmxsrDp16qSRI0cqIiLCNIXvpEmTNHDgQL399tuSpBo1aujVV1/16cJ348aN2rhxo44fP65hw4a5t2dkZKh06dIGJoO3Ufj6sMzMTD3xxBN68MEHVbZsWfd2M3Rgjh49qo0bNxod47qVLFlSAQEBstls+d7zihUrasCAAQYmKzwz/7u5bPfu3UpISFDp0qXVrFkzrVy5Uhs2bNB7771ndLQ/lZCQoHXr1ikyMlKSdNtttyk7O9vgVIWTlZWliRMnGh2jyIKDg9W+fXujYxRJTk6OpEv/fjp06CA/Pz9T/fGRnp6u5s2b65133pEk+fn5qWTJkgan+nNhYWFq2bKl9u7dq5YtW7q3BwYGqkmTJsYFg9dR+PqwJ554Qk888YTRMYokNDRUGRkZCgwMNDrKdWnYsKEaNmyoxx57zFQfsV/JzP9u/v73vys6OlqhoaHq1auXWrRoIZvNphdeeEFt2rQxOt41lSpVSjabzX3f6XQamOb61K1bV4cOHVJ4eLjRUYqkY8eOWrFihdq3b69SpUq5t5cpU8bAVIXTsGFDPf7443I4HJo8ebLS0tJM1bW22+3Kzc11/9s/ffq0z+evXr26qlevrlatWunWW281Og5uIApfH3a5a2RGQUFB6tq1q5o1a5Zv1MEsM77/+te/VKlSJQUFBemVV17R3r17NX78eD388MNGR7smM/+7OX78uBYsWKBq1aoVeOzdd981INH1ue+++7R+/Xq5XC6lpKRo0aJFevDBB42OVShPPfWUnnnmGd1xxx35CkczjGlIUvny5fXaa69pypQpkuSe8T1w4IDBya5t4sSJOnjwoEJDQ1WyZEllZGTo9ddfNzpWofXo0UODBw/W77//rrlz52rdunUaMWKE0bEKZeHChRo0aJDKlCmj3r17a//+/Zo8ebIiIiKMjgYv4eQ2H2bmEwbmzZt31e2DBw++wUmK5vIJYtu3b9fixYs1aNAgvf7664qJiTE62jXl5eVpzZo1OnDgQL6P2d98800DUxVeXl6eEhMTJV36OLJECfP8fZ6RkaG33npLmzdvliS1atVKY8eOzTdy4qsef/xxde3aVTVr1sz3MXvDhg0NTFV4rVq10uzZs1WrVi2f7zb+r8TERFWuXFmlSpXSP//5Tx04cEBRUVG65ZZbjI5WaDt37tQ333wjl8ulVq1aqUGDBkZHKpQnnnhC69ev17fffqvY2FiNHj1aAwYMUGxsrNHR4CXm+Y1iQWY8YeAysxS4f+TyL/6EhAR16tRJDzzwgGlObpswYYIcDocSEhL09NNPKz4+3jS/hH7++WcNGTLEPR+Yl5enuXPnqlatWgYnK5zAwEBTdequVKpUKT333HNGxyiyihUr6v777zc6RpEMHz5cq1evVnJysiZOnKimTZtq1KhRWrhwodHRCq1BgwZq0KCBcnJydP78eaPjXLcffvhBbdq0UUhISL5xJdx8zPVnscVcPmHg8n+EZjhh4LKsrCy9/fbb6tq1q7p27ap3331XWVlZRscqtNKlS2vRokX6/PPP1bRpU7lcLuXm5hodq1D27t2r6dOnKygoSM8//7w+/fRTHT582OhYhfL6669r2rRp+vLLL/Xll1/qjTfe0NSpU42OVWitW7fWggULdOrUKaOjXLdmzZppy5YtRscossaNG2vmzJnat2+fDh8+7L6ZweWf7d99952efvppTZ06VSdPnjQ6VqGNGDFC6enpunjxojp16qQOHTro73//u9GxCqV8+fKaOHGiNm7cqKZNmyovL08Oh8PoWPAiCl8fZsYTBi6bOnWqzpw5o7Fjx2rs2LE6c+aMe/bODN588039+uuvGjlypCpUqKDk5GR16tTJ6FiFcnk+0263KysrS0FBQTp79qzBqQonKysr3xnVTZo0MdUfTAsWLFBaWpqefPJJ9e3bV3FxcaZZ1eGzzz7TgAED9OCDD6pJkyZq3Lixqc5uX79+vTZu3KghQ4ZowIABGjBggJ5//nmjYxVKdna2fvvtN33zzTdq3LixJJnmEybp0qhGUFCQvv32WzVq1EjfffedadbBffvttxUWFqZ33nlHt9xyi06dOqW+ffsaHQtexKiDDzPzCQN79+7NdxGFBx54wFQrDYSFhWncuHHu+1WqVDHNL9FbbrlF58+fV7NmzdS/f3/ddtttCgkJMTpWoZQpU0YJCQlq1KiRJGnHjh2mOCv/sr/85S8aNWqURo4cqS1btmjVqlWaOnWqduzYYXS0a1qzZo3RETxyea7ajPr06aN27dqpSZMmuv/++5WcnKygoCCjYxXa5Que/PDDD2rRooXKlCljmiZNuXLl9Le//c19/6677jLlGugoPE5u83FmPWGgU6dOio6Odp/Uc+HCBUVFRZnmimJdu3a96pyXGc5wdzgcstvtcjqdiouLU3p6ujp37myKpeX27NmjYcOGyd/fXy6XS3l5eZo9e7bpZjf/+9//KiYmRvHx8br33nu1ZMkSoyNdl7Nnzyo5OVn16tUzOkqh3QwniF3mcDjkcDhMc/GfYcOGKTMzU0eOHFF8fLz8/PwUFRVlihPEGjdufNWf9Wa44h+KhsIXXrFo0SLFxcWpQ4cOkqQNGzboiSeeUL9+/QxOVjhXduiys7P1+eefq2LFinrppZcMTFV4GRkZOnr0qGlOCsvJyZG/v7+ysrLkcDh04sQJ2Ww2Va5cWXa73TRXUvroo4+0bt06ZWZmKjIyUhEREapUqZLRsQrF7JfNjYiI0OrVq3Xq1Cn16dNHTZs21a+//mqKE8SysrL0wQcfKDk5WW+//bZ++eUXJSYmqnXr1kZHK5SLFy9q69atCg8PV2hoqE6fPq1Dhw6pefPmRke7puPHj7u/zs7OVlxcnEqUKKFBgwYZmAreROHrw67WdQwKClK9evXUr18/BQQEGJSscL777jtt375d0qVZTTP8EPwjLpdLTz/9tFauXGl0lGv67rvvNGHCBNntdm3evFl79+7V+++/79MFQGRkpNauXavq1asX+DfvcrlUunRpDRo0SP379zcoYeGMHz9ekZGRplm790qdO3fWunXrFBsbq0OHDrkvm2uWT2ku/xtavny5srKy1L9/f0VERJii6zhq1ChVqFBB33zzjT7//HNlZmaqZ8+eppmTvdl0795dn332mdEx4CXM+PqwJk2a6OjRo+rcubMkKTY2VhUrVtTp06c1adIkzZw509iA19CiRQu1aNHC6BjFIiMjQ7/99pvRMQplzpw5Wr16tbtIvP/++3Xs2DGDU/25tWvXSpIOHjx41cfPnj2rqKgony98X3/9deXl5em///2vJHOtQ2z2y+ZeeYLY8OHDJZnnBLFDhw5p+vTp2rp1qyQpICDAFFf969Onj5YtW1ZgXODyxUPMOC6QnJxsmpOBUTTm+IlsUT/88IOio6Pd9x955BE99dRTio6O1uOPP25gsj82c+ZMvfLKKxo6dOhV56Zmz55tQKrrd2W33el0KiUlxVRn+laoUCHffbPMCv6R8uXLa+7cuUbHuCYzr0Ns9svmmvkEsf/97zM7O9sURfvl5ouZT4y8smh3Op3Ky8vLd2Izbj4Uvj7s999/V3Z2tnt5qssLg9tsNp+debz8Ee8jjzxicBLPXDnXaLfbFRoaqooVKxqYqPACAgL022+/uX+YJyQkmKYA+DM1atQwOsI1XV6H+PIyYNu2bdPUqVNNMSLzv5fNTU9PN9XFOKKiohQVFeW+X7lyZdOcVNigQQMtXLhQOTk5SkhI0JIlS9SqVSujY11TxYoV5XA4NGXKFH3wwQdGxymSK4v2EiVK6PbbbzfVJx24fhS+Pqx9+/aKiopS+/btJUmbNm1S27ZtlZmZqTvvvNPgdFd3+Yf1HXfcUWANUDN97GWWy7ReKSkpSVWrVtXIkSPVv39/paSkqFevXkpKStKCBQuMjmcJV1uH+K233jIw0bVdPrHw4sWLqlq1qqRLr6NMmTIKCwszNlwh/Pjjj3rwwQf13XffXfVxM4xbjRgxQh9++KECAgI0c+ZMtWrVSgMGDDA6VqHY7XadO3dOTqfTVJ8QSJdWzxg8eLB71ArWQOHrw0aMGKG6deu6VxgYPHiwu7CcN2+ekdGuacaMGQV+mFxtm6+62hI3l08sfOWVVwqMEviCl156STExMXr77bf10Ucf6aeffpIk1a9fX8HBwQanswYzrkMcFRWltWvXqn79+rLZbO75zMv/e+DAAaMj/qm1a9fqwQcf1IcffljgMZvNZorCt2TJkho4cKAGDhxodJQiqVu3rgYPHqyOHTvmO+na1997u92usmXL5vtkFTc/Cl8f16pVK1N85HXZ0aNHlZSUpIyMjHwdmPT0dFNdgatnz55KS0tT165dJUnr1q2T3W5XmTJl9Nprr/nkCgkXL17Upk2bdOLECXfRK0m7du2S5Pu/hG4GY8eOda9DLEm5ubmaM2eOwan+3LVOLPR1l8cxPv74Y4OTFF12drbWr1+v5ORk98UgJOnVV181MFXhXf7jaMWKFe5tZvmjIywsTD179lTbtm3d685Ll34H4ObEcmY+7MiRI1qwYEGBH4a+fBGFtWvXKiYmRj///LNq167t3h4YGKioqCi1bNnSuHDX4cknn9SqVavybevatavWrFmjDh066PPPPzco2R/76quvFB0drZ07d+Z776VLv4Q++ugjg5JZS25urhITEyVd+qV6+UQ3s8jJyZHD4XDf9/WO9ZWOHTumY8eO5ctvhuLrhRdeUG5ururUqZNvvnTw4MEGprKGQYMGFfhELD093ec/VUXR0fH1YS+99JLatWunLl26mGbYPjIyUpGRkYqJiVGXLl2MjlNkaWlpOnfunG699VZJl040zMjIkCSfLWRat26t1q1b680339SYMWOMjmMp//tpRmhoqKRLqzrk5eWZonj84osv9Oabb+r06dOmGnW4bMaMGVq3bp3CwsLcs6Zm6ToePXpUGzduNDqGR65ct71x48ameN8l6cSJE3r//ffzbYuMjDQoDW4ECl8f5nQ69cILLxgdo0i6dOmi9PR0JSYmKjs72739oYceMjBV4fXq1UsRERHuH95btmxRv379lJmZqQceeMDgdH+OovfGu3I+VpJ7PtxMxePMmTM1d+5c1a5d23QnKUmXPvH4+uuvTfFHxv8KDQ1VRkaGKS4rfjXvvvuuNm/e7L5S5zvvvKNdu3a511P2RXl5ecrNzZXT6dTFixfd/+2abSwP14/C14fVq1dPBw8eVPXq1Y2Oct02bNig6dOnKy0tTRUrVtSxY8dUvXp105zc9swzz+ihhx5yn1jYo0cP9/8PEyZMMDIafJBZ52OvVKFCBdWpU8foGEVWqVIln/005lqCgoLUtWtXNWvWLN+avmaZ8f3iiy+0du1a94xs7969FRkZ6dOF78KFC93jDPXq1XNvDwwMNNWa7bh+FL4+bM+ePYqJiVFYWJhKlSrl7h758ozvZQsXLlRMTIyee+45rVu3Tv/617+0adMmo2Ndl/DwcIWHh+vs2bNKTk42Og7gVb169dJ7772nNm3a5DvD/d577zUwVeGNHj1aL7zwgpo2bZqveDTDSUphYWGmWDrujwQHB+frtJcqVcrnV5IZPHiwBg8erClTptDMsBgKXx82duzYAtuudjU0X1SiRAmVL1/efZJJ06ZNNWvWLINTFV6PHj30wQcfyOVyqXPnzgoODlbz5s3zXdgCuJmcPn1aS5cu1bp16/LNyH799dcGJyucRYsW6ddff9WBAwdMc07EZWY/ia1+/frq16+fezZ2/fr1+dZW9uV5X4pe66Hw9WE1atTQokWLdPDgwXxzsmY4O9/f318ul0t33323Pv74Y9155526cOGC0bEK7cKFCwoKClJsbKw6deqkkSNHKiIigsIXN62PP/5YX375pWmuUPi/9u3bp02bNpmmOSBdOiHvz5hl1OHyDHt0dLR72759+7Rv3z7TnGAI66Dw9WFjx45VtWrVlJSUpGHDhmnNmjWqVauW0bEKZdiwYcrIyNDIkSM1adIkpaena+LEiUbHKrScnBxJly7326FDB/n5+ZmuiwRcj8qVK5u26JWkqlWr6sKFC/kuoODrLs/EHjt2TD/88IPatGkj6dKJemY5EdjpdGrcuHGmPBcF1sQ6vj7siSee0Pr169WpUyfFxcUpJydHvXv31sqVK42OdtObNGmSduzYIYfDofj4eGVlZelvf/ubYmJijI4GeMX06dN1+vRptWvXLt+Mr1m6dS+99JL27dtnyhPEevfurdmzZ+u2226TdGn5xGHDhpni0z1J7t9RgBnQ8fVhl394lyxZUufOndMtt9yi1NRUg1MVTkZGhubPn+9e17FJkyYaOHCgaZbrmThxog4ePKjQ0FCVLFlS6enp7itEATejn3/+WVL+K6CZ6WPqe+65R/fcc4/RMYrkt99+cxe9knTbbbfpt99+MzDR9bn77ruVkpKiu+66y+gowDXR8fVhI0eO1Pjx47V27VqtXLlSQUFBCg0N1bvvvmt0tGsaOnSoAgMD1a1bN0lSTEyM0tLSfP7yrTk5OfL39//DdRzNuEYoAN82dOhQBQUF5ft5ef78eZ//eXlZ3759tXv3bj344IP5Lvs7e/ZsA1MBV0fhaxI7d+5Uenq6mjVrphIlfL9R3759+wJXIrraNl8TGRmptWvXqnr16vkuSCDJNBciAK5HcnKyQkNDdfjw4as+7uvLmW3cuFHt27fXJ598ctXHzbCcWUZGht5//30lJCRIkho1aqRBgwaZ5hOyP1qfnSugwRf5fgUFSVKDBg2MjnBdKlasqNTUVJUrV07SpZm1kJAQg1Nd26effqqsrCz99NNPRkcBbojXX39dH3zwgQYMGFDgMTMsZ/bf//5X7du3d49qmFFgYKCpV4yhwIWZ0PGFVwwfPlw//vijHnnkEUnSt99+qwYNGuiOO+6Q5LsnnFzu9F6NzWbT/v37b3AiAFawdetWHThwIN/SlWZZ33fo0KFX/bnJqAN8ER1feMW9996b7yPS7t27G5im8C5fenb+/Pny9/dXVFSUXC6XVq1apdzcXIPTAd4zbNiwAoXK1bb5qg0bNqh58+YKDAzU7NmztWfPHr300kumWAJy1qxZ2rt3rw4fPqxHH31UX3/9tZo0aWJ0rEK73OCQpOzsbG3atEnVqlUzMBHwJ1wACujcuXOBbZGRkQYkAW6Mq/2b79ixowFJiuZy1t27d7u6devmWr9+vSsqKsrgVIXTsWNHV25urqtTp04ul8vlOnXqlKtfv34Gpyq67Oxs1zPPPGN0DOCq6PiiWN0MJ5pI0sWLF3X06FHdfffdki4tMP9HKz0AZvbZZ58pOjpaSUlJ7lUFJCk9PV1hYWEGJrs+l0/6/de//qUnn3xSnTp10j/+8Q+DUxWOv7+/SpQoIZvNptzcXIWEhOjUqVNGxyoym82m06dPGx0DuCoKXxSrm+FEE0kaMWKEunfvrtq1a0uS9u/fr6lTpxqcCih+TZs21d13362pU6fmm70PDAxUeHi4gcmuj81m04YNG7RhwwbNnz9fkkwznhQQEKCsrCzVr19fo0ePVoUKFVS6dGmjYxXalTO+LpdLBw8eNNWoBqyFk9uAP3D27Fnt3r1bklSvXj33ChXAzSwzM1OSTHXpX0n66aef9OGHH6pRo0bq06ePkpKS9PHHH+u1114zOto1/fbbbwoODpbD4dCSJUuUkpKiIUOGqFKlSkZHK5QrlzMrUaKEQkNDVa9ePeMCAX+CwhdesWjRInXv3l233nqrpEvLma1Zs0b9+vUzNhiAq/rll1/06quv6j//+Y9sNpvuu+8+TZ8+nZOUboARI0ZoypQpKlmypCIiIpSamqoXXnhBzz33nNHRCuV/8//+++96/vnnTZMf1uJndADcnD7//HN30StdugRnfHy8cYEA/KkxY8aoV69e2rNnj3bv3q1evXppzJgxRscqtLfeekvp6enKy8tTjx49VK9ePcXGxhodq1ASExMVFBSkb7/9Vo0bN9Y///lPrVu3zuhYhXZl/kaNGum7774zVX5YC4UvvOJqHyQ4HA4DkgAojAsXLqhz586y2Wyy2WyKiIgw1Qmd33//vYKCgrR161aFhIRo06ZNpjm5LS8vT5L0ww8/qHnz5ipdurT8/Mzz6/nK/C1atFCZMmVMlR/Wwr9MeEXVqlW1ZMkSuVwuOZ1O/eMf/1CVKlWMjgXgD9SqVUs7d+503//xxx/dJ3eayQ8//KA2bdooJCTkDy9G42uqVaumfv366ZtvvlGTJk108eJFoyNdF7Pnh7Uw4wuvOH36tF555RXt2rVLNptN9evX14wZM0xx2WLAiiIiInTo0KF8S/jdd999KlmypCRp9erVRsa7pr59+6pKlSr65z//qbVr1yogIECRkZGKi4szOto1Xbx4UVu3blV4eLhCQ0N1+vRpHTp0SM2bNzc6WqGYPT+shcIXXnXhwgVJUtmyZQ1OAuDP7NixQ9KlVR1sNluB/2YbNmxoRKxCS01N1fr161WvXj3Vq1dPKSkp2rFjh7p06WJ0NAA+hMIXxSo5OVmhoaE6fPjwVR+/8jLGAHzHsWPHNHLkSB04cEA2m001a9bUzJkzFRoaanS0QsvIyNDRo0dNcZliAMag8EWxev755/XBBx+oVatWBR6z2Wz6+uuvDUgF4Fr69u2rDh06qGvXrpKkmJgYxcfHa8mSJQYnK5zvvvtOEyZMkN1u1+bNm7V37169//77WrhwodHRAPgQrtyGYvXBBx9IkjZv3mxwEgDXIzU1Nd8li7t27aqPPvrIwETXZ86cOVq9erX69+8vSbr//vt17Ngxg1MB8DWs6gCvGDZsWKG2AfANfn5+OnLkiPt+YmKi7Ha7gYmuX4UKFfLd9/f3NygJAF9FxxdecbVOy5W/VAH4lhEjRqhnz56qUaOGJOngwYOaMWOGwakKLyAgQL/99pt7CbOEhAQFBQUZnAqAr2HGF8Xqs88+U3R0tI4cOZLvUqfp6ekKCwtj3g7wYampqdq9e7ckqW7duipXrpzBiQpvz549mjhxolJSUlS9enUlJSVpwYIFplyLGID3UPiiWB0/flwpKSmaOnWqJkyY4N4eGBio8PBw0310CsA80tPT9dNPP0mS6tevr+DgYIMTAfA1FL4AgJuCmTvWAG4MCl94xZEjR7RgwQIlJye7r+Mu+f7VnwCY05dffqnXXntNtWvXlsvl0oEDBzR16lS1bt3a6GgAfAiFL7yic+fOateunerWrZtvvMHXr/4EwJzat2+v+fPnKywsTJKUlJSkgQMHauPGjQYnA+BLWNUBXuF0OvXCCy8YHQOARZQqVcpd9EpS1apVVbp0aQMTAfBFrOMLr6hXr54OHjxodAwAFvHoo49qwYIF+vXXX3XmzBktXLhQjz76qC5evKisrCyj4wHwEYw6wCs6d+6sw4cPKywsTKVKlZLL5ZLNZmPGF4BXVK9e/Q8fs9lsOnDgwA1MA8BXUfjCK3bs2FFgm81m00MPPWRAGgAAAApfeEl6eroWLVqkgwcPKjs72739o48+MjAVAACwMmZ84RVjx46V3W5XUlKSunfvLrvdrjp16hgdCwAAWBiFL7zi6NGjGj58uEqXLq2OHTvqgw8+0M6dO42OBQAALIzCF17h7+8vSSpZsqTOnTunkiVLKjU11eBUAADAyljHF15RtWpVnTt3Tp06dVJUVJSCgoJUq1Yto2MBAAAL4+Q2eN3OnTuVnp6uZs2aqUQJ/tYCAADGoPAFAACAJTDjCwAAAEug8AUAAIAlUPgCAADAEih8AQAAYAn/Hz1jfzQHpyJGAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Twitter data preprocessor from the paper: **\"Deep lstm with attention for message-level and topic-based sentiment analysis.\"**","metadata":{}},{"cell_type":"code","source":"# imports\nfrom torch.utils.data import Dataset\nfrom transformers import BertTokenizer, AutoTokenizer\nfrom tqdm import tqdm\nimport torch\nimport pandas as pd\nfrom ekphrasis.classes.tokenizer import SocialTokenizer\nfrom ekphrasis.classes.preprocessor import TextPreProcessor\n\ndef twitter_preprocessor():\n    \"\"\" preprocess the tweets according to the paper: Deep lstm with attention for message-level and \n    topic-based sentiment analysis.\n    Normalizes URLs, usernames, contact info in the tweets,\n    tokenizes the data\n    \"\"\"\n    preprocessor = TextPreProcessor(\n        normalize=['url', 'email', 'phone', 'user'],\n        annotate={\"hashtag\", \"elongated\", \"allcaps\", \"repeated\", 'emphasis', 'censored'},\n        all_caps_tag=\"wrap\",\n        fix_text=False,\n        segmenter=\"twitter_2018\",\n        corrector=\"twitter_2018\",\n        unpack_hashtags=True,\n        unpack_contractions=True,\n        spell_correct_elong=False,\n        tokenizer=SocialTokenizer(lowercase=True).tokenize).pre_process_doc\n    return preprocessor\n\n# Create a preprocess object and keep it ready for use in the dataset class\npreprocessor = twitter_preprocessor()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T01:55:15.310883Z","iopub.execute_input":"2022-12-12T01:55:15.311725Z","iopub.status.idle":"2022-12-12T01:55:53.142765Z","shell.execute_reply.started":"2022-12-12T01:55:15.311682Z","shell.execute_reply":"2022-12-12T01:55:53.141576Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n/opt/conda/lib/python3.7/site-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n","output_type":"stream"},{"name":"stdout","text":"Word statistics files not found!\nDownloading... done!\nUnpacking... done!\nReading twitter_2018 - 1grams ...\ngenerating cache file for faster loading...\nreading ngrams /root/.ekphrasis/stats/twitter_2018/counts_1grams.txt\nReading twitter_2018 - 2grams ...\ngenerating cache file for faster loading...\nreading ngrams /root/.ekphrasis/stats/twitter_2018/counts_2grams.txt\nReading twitter_2018 - 1grams ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Dataset class to train and evaluate the model.\n- Reads data from files and preprocess the tweets to tokens\n- Runs the tokens through BERT tokenizer to generate IDs for each token and returns a batch of this data.","metadata":{}},{"cell_type":"code","source":"# Dataset class that reads tweets and labels from the files and prepares batches of data for training, test.\nclass DataClass(Dataset):\n    def __init__(self, args, filename):\n        self.args = args\n        self.filename = filename\n        self.max_length = int(args['--max-length'])\n        self.data, self.labels = self.load_dataset()\n        \n        self.bert_tokeniser = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n        self.inputs, self.lengths, self.label_indices = self.process_data()\n\n    def load_dataset(self):\n        \"\"\"\n        :return: dataset after being preprocessed and tokenised\n        \"\"\"\n        df = pd.read_csv(self.filename, sep='\\t')\n        x_train, y_train = df.Tweet.values, df.iloc[:, 2:].values\n        return x_train, y_train\n\n    def process_data(self):\n        desc = \"PreProcessing dataset {}...\".format('')\n        \n        segment_a = \"anger anticipation disgust fear joy love optimism hopeless sadness surprise or trust?\"\n        label_names = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\",\n                       \"love\", \"optimism\", \"hopeless\", \"sadness\", \"surprise\", \"trust\"]\n\n        inputs, lengths, label_indices = [], [], []\n        for x in tqdm(self.data, desc=desc):\n            x = ' '.join(preprocessor(x))\n            x = self.bert_tokeniser.encode_plus(segment_a,\n                                                x,\n                                                add_special_tokens=True,\n                                                max_length=self.max_length,\n                                                pad_to_max_length=True,\n                                                truncation=True)\n            input_id = x['input_ids']\n            input_length = len([i for i in x['attention_mask'] if i == 1])\n            inputs.append(input_id)\n            lengths.append(input_length)\n\n            #label indices\n            label_idxs = [self.bert_tokeniser.convert_ids_to_tokens(input_id).index(label_names[idx])\n                             for idx, _ in enumerate(label_names)]\n            label_indices.append(label_idxs)\n\n        inputs = torch.tensor(inputs, dtype=torch.long)\n        data_length = torch.tensor(lengths, dtype=torch.long)\n        label_indices = torch.tensor(label_indices, dtype=torch.long)\n        return inputs, data_length, label_indices\n\n    def __getitem__(self, index):\n        inputs = self.inputs[index]\n        labels = self.labels[index]\n        label_idxs = self.label_indices[index]\n        length = self.lengths[index]\n        return inputs, labels, length, label_idxs\n\n    def __len__(self):\n        return len(self.inputs)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T01:55:59.849998Z","iopub.execute_input":"2022-12-12T01:55:59.851034Z","iopub.status.idle":"2022-12-12T01:55:59.917664Z","shell.execute_reply.started":"2022-12-12T01:55:59.850979Z","shell.execute_reply":"2022-12-12T01:55:59.916609Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Installing the exact version of transformer is crucial for the model to run.","metadata":{}},{"cell_type":"code","source":"# package installation for the transformer model\n!pip install transformers==3.0.2","metadata":{"execution":{"iopub.status.busy":"2022-12-12T01:56:04.908853Z","iopub.execute_input":"2022-12-12T01:56:04.909211Z","iopub.status.idle":"2022-12-12T01:56:14.095373Z","shell.execute_reply.started":"2022-12-12T01:56:04.909181Z","shell.execute_reply":"2022-12-12T01:56:14.094215Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers==3.0.2 in /opt/conda/lib/python3.7/site-packages (3.0.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (1.21.6)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (4.31.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.0.53)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (21.3)\nRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.97)\nRequirement already satisfied: tokenizers==0.8.1.rc1 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.8.1rc1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (3.7.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2.1.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (8.0.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (1.15.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers==3.0.2) (4.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.2) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.2) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### SpanEmo model.\n- Contains BERT encoder as the first part of the network. \n- Features from BERT are passed through a feed forward network to generate class probabilities for each class.\n- For the label correlation aware loss (joint2), we use the label graph (label-correlation data from the train split) as attention to generate a better mapping in the soft BCE loss.\n- See paper: **'Review-Driven Multi-Label Music Style Classification by Exploiting Style Correlations'** for more details on the LCA loss used in 'joint2' loss function.","metadata":{}},{"cell_type":"code","source":"#from transformers.modeling_bert import BertModel\nfrom transformers import BertModel #, AutoModel\n#from transformers.models.bert.modeling_bert import BertModel\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\nimport transformers \n\n\nclass BertEncoder(nn.Module):\n    def __init__(self):\n        super(BertEncoder, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.feature_size = self.bert.config.hidden_size\n\n    def forward(self, input_ids):\n        \"\"\"\n        :param input_ids: list[str], list of tokenised sentences\n        :return: last hidden representation, torch.tensor of shape (batch_size, seq_length, hidden_dim)\n        \"\"\"\n        if int((transformers.__version__)[0]) == 4:\n            last_hidden_state = self.bert(input_ids=input_ids).last_hidden_state\n        else: #transformers version should be as indicated in the requirements.txt file\n            last_hidden_state, pooler_output = self.bert(input_ids=input_ids)\n        return last_hidden_state\n\n\nclass SpanEmo(nn.Module):\n    def __init__(self, output_dropout=0.1, joint_loss='joint', alpha=0.2):\n        \"\"\" casting multi-label emotion classification as span-extraction\n        :param output_dropout: The dropout probability for output layer\n        :param joint_loss: which loss to use cel|corr|cel+corr\n        :param alpha: control contribution of each loss function in case of joint training\n        \"\"\"\n        super(SpanEmo, self).__init__()\n        self.bert = BertEncoder()\n        self.joint_loss = joint_loss\n        self.alpha = alpha\n        \n        self.ffn = nn.Sequential(\n            nn.Linear(self.bert.feature_size, self.bert.feature_size),\n            nn.Tanh(),\n            nn.Dropout(p=output_dropout),\n            nn.Linear(self.bert.feature_size, 1)\n        )\n        \n        if self.joint_loss == 'joint2':\n            # temperature parameter for the soft BCE loss to be used in LCA loss (joint2).\n            self.temp = 5.0\n\n            #Label correlation matrix as a parameter. \n            #See eq 5 in paper: Review-Driven Multi-Label Music Style Classification by Exploiting Style Correlations\n            self.label_corr = torch.nn.Linear(11, 11, bias=False)\n            # Initializing the label graph layer with correlation matrix from train data.\n            with torch.no_grad():\n                self.label_corr.weight.copy_(torch.tensor(label_graph, dtype=torch.float))\n\n    def forward(self, batch, device):\n        \"\"\"\n        :param batch: tuple of (input_ids, labels, length, label_indices)\n        :param device: device to run calculations on\n        :return: loss, num_rows, y_pred, targets\n        \"\"\"\n        #prepare inputs and targets\n        inputs, targets, lengths, label_idxs = batch\n        inputs, num_rows = inputs.to(device), inputs.size(0)\n        label_idxs, targets = label_idxs[0].long().to(device), targets.float().to(device)\n\n        #Bert encoder\n        last_hidden_state = self.bert(inputs)\n\n        # FFN---> 2 linear layers---> linear layer + tanh---> linear layer\n        # select span of labels to compare them with ground truth ones\n        logits = self.ffn(last_hidden_state).squeeze(-1).index_select(dim=1, index=label_idxs)\n\n        #Loss Function\n        if self.joint_loss == 'joint':\n            cel = F.binary_cross_entropy_with_logits(logits, targets).cuda()\n            cl = self.corr_loss(logits, targets)\n            loss = ((1 - self.alpha) * cel) + (self.alpha * cl)\n        elif self.joint_loss == 'cross-entropy':\n            loss = F.binary_cross_entropy_with_logits(logits, targets).cuda()\n        elif self.joint_loss == 'corr_loss':\n            loss = self.corr_loss(logits, targets)\n        # New loss function using label graph training parameter and BCE loss with temperature.\n        elif self.joint_loss == 'joint2':\n            cel = F.binary_cross_entropy_with_logits(logits, targets).cuda()\n            cl = self.lca_loss(logits, targets)\n            loss = ((1 - self.alpha) * cel) + (self.alpha * cl)\n\n        y_pred = self.compute_pred(logits)\n        return loss, num_rows, y_pred, targets.cpu().numpy()\n\n    def lca_loss(self, y_hat, y_true):\n        \"\"\" LCA loss that uses the graph_labels to weight the label correlation.\n        :param y_hat: output raw probabilities from the model.\n        :param y_true: target labels.\n        :return lca loss\n        \"\"\"\n        #y_hat_dash = torch.matmul(y_hat.sigmoid(), self.label_corr)\n        # Matrix multiplication between the label graph and the outputs from the model.\n        y_hat_dash = self.label_corr(y_hat.sigmoid())\n        \n        # Softmax dimension based on the label_corr position in the matrix multiplication.\n        label_corr_soft = F.softmax(self.label_corr.weight/self.temp, dim=0)\n        y_true_dash = torch.matmul(y_true, label_corr_soft)\n\n        return F.binary_cross_entropy_with_logits(y_hat_dash, y_true_dash).cuda()\n    \n    @staticmethod\n    def corr_loss(y_hat, y_true, reduction='mean'):\n        \"\"\"\n        :param y_hat: model predictions, shape(batch, classes)\n        :param y_true: target labels (batch, classes)\n        :param reduction: whether to avg or sum loss\n        :return: loss\n        \"\"\"\n        loss = torch.zeros(y_true.size(0)).cuda()\n        for idx, (y, y_h) in enumerate(zip(y_true, y_hat.sigmoid())):\n            y_z, y_o = (y == 0).nonzero(), y.nonzero()\n            if y_o.nelement() != 0:\n                output = torch.exp(torch.sub(y_h[y_z], y_h[y_o][:, None]).squeeze(-1)).sum()\n                num_comparisons = y_z.size(0) * y_o.size(0)\n                loss[idx] = output.div(num_comparisons)\n        return loss.mean() if reduction == 'mean' else loss.sum()\n        \n    @staticmethod\n    def compute_pred(logits, threshold=0.5):\n        \"\"\"\n        :param logits: model predictions\n        :param threshold: threshold value\n        :return:\n        \"\"\"\n        y_pred = torch.sigmoid(logits) > threshold\n        return y_pred.float().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T02:03:20.857789Z","iopub.execute_input":"2022-12-12T02:03:20.858146Z","iopub.status.idle":"2022-12-12T02:03:20.881457Z","shell.execute_reply.started":"2022-12-12T02:03:20.858116Z","shell.execute_reply":"2022-12-12T02:03:20.880362Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Training and Testing utils\n\nNext, we define trainer, early stopper classes to help run the training, validation, and early stopping if the validation loss doesn't go down after a set number of epochs.\n- EarlyStopper:\n    - Checks if the validation loss is less than previous epoch, if yes saves the checkpoint if not, increments the early stop counter.\n    - When the early stop counter reaches 10, the training is terminated.\n- Trainer:\n    - Creates an optimizer with different learning rates for BERT, FFN, and the label graph parameters to optimize them.\n    - Optimize the model by running back propogation on the combined loss function.\n    - Predict emotions from a given tweet and return the logits.\n- Evaluate:\n    - Runs the model on the entire test/validation data and generates F1-micro/macro, jaccard score metrics.","metadata":{}},{"cell_type":"code","source":"from fastprogress.fastprogress import format_time, master_bar, progress_bar\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import f1_score, jaccard_score\nimport torch.nn.functional as F\nimport numpy as np\nimport torch\nimport time\n\n\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\n    Taken from https://github.com/Bjarten/early-stopping-pytorch\"\"\"\n\n    def __init__(self, filename, patience=7, verbose=True, delta=0):\n        \"\"\"\n        :param patience: How long to wait after last time validation loss improved.\n        :param verbose: If True, prints a message for each validation loss improvement.\n        :param delta: Minimum change in the monitored quantity to qualify as an improvement.\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.cur_date = filename\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decreases.\"\"\"\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), '/kaggle/working/' + self.cur_date + '_checkpoint.pt')\n        self.val_loss_min = val_loss\n\n\nclass Trainer(object):\n    \"\"\"\n    Class to encapsulate training and validation steps for a pipeline. Based off the \"Tonks Library\"\n    :param model: PyTorch model to use with the Learner\n    :param train_data_loader: dataloader for all of the training data\n    :param val_data_loader: dataloader for all of the validation data\n    :param filename: the best model will be saved using this given name (str)\n    \"\"\"\n\n    def __init__(self, model, train_data_loader, val_data_loader, filename):\n        self.model = model\n        self.train_data_loader = train_data_loader\n        self.val_data_loader = val_data_loader\n        self.filename = filename\n        self.early_stop = EarlyStopping(self.filename, patience=10)\n\n    def fit(self, num_epochs, args, device='cuda:0'):\n        \"\"\"\n        Fit the PyTorch model\n        :param num_epochs: number of epochs to train (int)\n        :param args:\n        :param device: str (defaults to 'cuda:0')\n        \"\"\"\n        optimizer, scheduler, step_scheduler_on_batch = self.optimizer(args)\n        self.model = self.model.to(device)\n        pbar = master_bar(range(num_epochs))\n        headers = ['Train_Loss', 'Val_Loss', 'F1-Macro', 'F1-Micro', 'JS', 'Time']\n        pbar.write(headers, table=True)\n        for epoch in pbar:\n            epoch += 1\n            start_time = time.time()\n            self.model.train()\n            overall_training_loss = 0.0\n            for step, batch in enumerate(progress_bar(self.train_data_loader, parent=pbar)):\n                loss, num_rows, _, _ = self.model(batch, device)\n                overall_training_loss += loss.item() * num_rows\n\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                optimizer.step()\n                if step_scheduler_on_batch:\n                    scheduler.step()\n                optimizer.zero_grad()\n\n            if not step_scheduler_on_batch:\n                scheduler.step()\n\n            overall_training_loss = overall_training_loss / len(self.train_data_loader.dataset)\n            overall_val_loss, pred_dict = self.predict(device, pbar)\n            y_true, y_pred = pred_dict['y_true'], pred_dict['y_pred']\n\n            str_stats = []\n            stats = [overall_training_loss,\n                     overall_val_loss,\n                     f1_score(y_true, y_pred, average=\"macro\"),\n                     f1_score(y_true, y_pred, average=\"micro\"),\n                     jaccard_score(y_true, y_pred, average=\"samples\")]\n\n            for stat in stats:\n                str_stats.append(\n                    'NA' if stat is None else str(stat) if isinstance(stat, int) else f'{stat:.4f}'\n                )\n            str_stats.append(format_time(time.time() - start_time))\n            print('epoch#: ', epoch)\n            pbar.write(str_stats, table=True)\n            self.early_stop(overall_val_loss, self.model)\n            if self.early_stop.early_stop:\n                print(\"Early stopping\")\n                break\n                \n    def optimizer(self, args):\n        \"\"\"\n        :param args: object\n        \"\"\"\n        optimizer = AdamW([\n            {'params': self.model.bert.parameters()},\n            {'params': self.model.label_corr.parameters()},\n            {'params': self.model.ffn.parameters(),\n             'lr': float(args['--ffn-lr'])},\n        ], lr=float(args['--bert-lr']), correct_bias=True)\n        num_train_steps = (int(len(self.train_data_loader.dataset)) /\n                           int(args['--train-batch-size'])) * int(args['--max-epoch'])\n        num_warmup_steps = int(num_train_steps * 0.1)\n        scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                    num_warmup_steps=num_warmup_steps,\n                                                    num_training_steps=num_train_steps)\n        step_scheduler_on_batch = True\n        return optimizer, scheduler, step_scheduler_on_batch\n\n    def predict(self, device='cuda:0', pbar=None):\n        \"\"\"\n        Evaluate the model on a validation set\n        :param device: str (defaults to 'cuda:0')\n        :param pbar: fast_progress progress bar (defaults to None)\n        :returns: overall_val_loss (float), accuracies (dict{'acc': value}, preds (dict)\n        \"\"\"\n        current_size = len(self.val_data_loader.dataset)\n        preds_dict = {\n            'y_true': np.zeros([current_size, 11]),\n            'y_pred': np.zeros([current_size, 11])\n        }\n        overall_val_loss = 0.0\n        self.model.eval()\n        with torch.no_grad():\n            index_dict = 0\n            for step, batch in enumerate(progress_bar(self.val_data_loader, parent=pbar, leave=(pbar is not None))):\n                loss, num_rows, y_pred, targets = self.model(batch, device)\n                overall_val_loss += loss.item() * num_rows\n\n                current_index = index_dict\n                preds_dict['y_true'][current_index: current_index + num_rows, :] = targets\n                preds_dict['y_pred'][current_index: current_index + num_rows, :] = y_pred\n                index_dict += num_rows\n\n        overall_val_loss = overall_val_loss / len(self.val_data_loader.dataset)\n        return overall_val_loss, preds_dict\n\nclass EvaluateOnTest(object):\n    \"\"\"\n    Class to encapsulate evaluation on the test set. Based off the \"Tonks Library\"\n    :param model: PyTorch model to use with the Learner\n    :param test_data_loader: dataloader for all of the validation data\n    :param model_path: path of the trained model\n    \"\"\"\n    def __init__(self, model, test_data_loader, model_path):\n        self.model = model\n        self.test_data_loader = test_data_loader\n        self.model_path = model_path\n\n    def predict(self, device='cuda:0', pbar=None):\n        \"\"\"\n        Evaluate the model on a validation set\n        :param device: str (defaults to 'cuda:0')\n        :param pbar: fast_progress progress bar (defaults to None)\n        :returns: None\n        \"\"\"\n        self.model.to(device).load_state_dict(torch.load(self.model_path))\n        self.model.eval()\n        current_size = len(self.test_data_loader.dataset)\n        preds_dict = {\n            'y_true': np.zeros([current_size, 11]),\n            'y_pred': np.zeros([current_size, 11])\n        }\n        start_time = time.time()\n        with torch.no_grad():\n            index_dict = 0\n            for step, batch in enumerate(progress_bar(self.test_data_loader, parent=pbar, leave=(pbar is not None))):\n                _, num_rows, y_pred, targets = self.model(batch, device)\n                current_index = index_dict\n                preds_dict['y_true'][current_index: current_index + num_rows, :] = targets\n                preds_dict['y_pred'][current_index: current_index + num_rows, :] = y_pred\n                index_dict += num_rows\n\n        y_true, y_pred = preds_dict['y_true'], preds_dict['y_pred']\n        str_stats = []\n        stats = [f1_score(y_true, y_pred, average=\"macro\"),\n                 f1_score(y_true, y_pred, average=\"micro\"),\n                 jaccard_score(y_true, y_pred, average=\"samples\")]\n\n        for stat in stats:\n            str_stats.append(\n                'NA' if stat is None else str(stat) if isinstance(stat, int) else f'{stat:.4f}'\n            )\n        str_stats.append(format_time(time.time() - start_time))\n        headers = ['F1-Macro', 'F1-Micro', 'JS', 'Time']\n        print(' '.join('{}: {}'.format(*k) for k in zip(headers, str_stats)))","metadata":{"execution":{"iopub.status.busy":"2022-12-12T01:56:21.416091Z","iopub.execute_input":"2022-12-12T01:56:21.416634Z","iopub.status.idle":"2022-12-12T01:56:21.475420Z","shell.execute_reply.started":"2022-12-12T01:56:21.416589Z","shell.execute_reply":"2022-12-12T01:56:21.474307Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Train\n- Main code block that sets the parameters for training. Calls the trainer object to run the training.\n- Checkpoints are saved in the 'kaggle/working/' directory based on the time and date of the experiment.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nOptions:\n    --loss-type=<str>                 Which loss to use cross-entropy|corr_loss|joint. [default: joint]\n    --max-length=<int>                text length [default: 128]\n    --output-dropout=<float>          prob of dropout applied to the output layer [default: 0.1]\n    --seed=<int>                      fixed random seed number [default: 42]\n    --train-batch-size=<int>          batch size [default: 32]\n    --eval-batch-size=<int>           batch size [default: 32]\n    --max-epoch=<int>                 max epoch [default: 20]\n    --ffn-lr=<float>                  ffn learning rate [default: 0.001]\n    --bert-lr=<float>                 bert learning rate [default: 2e-5]\n    --dev-path=<str>                  file path of the dev set [default: '/semeval2018/2018-E-c-En-dev/2018-E-c-En-dev.txt']\n    --train-path=<str>                file path of the train set [default: '/semeval2018/2018-E-c-En-train/2018-E-c-En-train.txt']\n    --alpha-loss=<float>              weight used to balance the loss [default: 0.2]\n\"\"\"\n\nfrom torch.utils.data import DataLoader\nimport torch\nimport datetime\nimport json\nimport numpy as np\n\n# making arg parser as a dictionary to run in a notebook.\nargs = {}\nargs['--loss-type'] = 'joint2' #'joint' #'corr_loss' #'cross-entropy' #'joint'\nargs['--max-length'] = int(128)\nargs['--output-dropout'] = 0.1\nargs['--seed'] = 42\nargs['--train-batch-size'] = int(32)\nargs['--eval-batch-size'] = int(32)\nargs['--max-epoch'] = int(20)\nargs['--ffn-lr'] = 0.001\nargs['--bert-lr'] = 2e-5\nargs['--dev-path'] = '../input/semeval2018/2018-E-c-En-dev/2018-E-c-En-dev.txt'\nargs['--train-path'] = '../input/semeval2018/2018-E-c-En-train/2018-E-c-En-train.txt'\nargs['--alpha-loss'] = 0.2\n\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nif str(device) == 'cuda:0':\n    print(\"Currently using GPU: {}\".format(device))\n    np.random.seed(int(args['--seed']))\n    torch.cuda.manual_seed_all(int(args['--seed']))\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nelse:\n    print(\"Currently using CPU\")\n\n#####################################################################\n# Save hyper-parameter values ---> config.json\n# Save model weights ---> filename.pt using current time\n#####################################################################\nnow = datetime.datetime.now()\nfilename = now.strftime(\"%Y-%m-%d-%H:%M:%S\")\nfw = open('/kaggle/working/' + filename + '.json', 'a')\nmodel_path = '/kaggle/working/'+ filename + '.pt'\nargs['--checkpoint-path'] = model_path\njson.dump(args, fw, sort_keys=True, indent=2)\n\n#####################################################################\n# Define Dataloaders\n#####################################################################\ntrain_dataset = DataClass(args, args['--train-path'])\ntrain_data_loader = DataLoader(train_dataset,\n                               batch_size=int(args['--train-batch-size']),\n                               shuffle=True\n                               )\nprint('The number of training batches: ', len(train_data_loader))\ndev_dataset = DataClass(args, args['--dev-path'])\ndev_data_loader = DataLoader(dev_dataset,\n                             batch_size=int(args['--eval-batch-size']),\n                             shuffle=False\n                             )\nprint('The number of validation batches: ', len(dev_data_loader))\n\n#############################################################################\n# Define Model & Training Pipeline\n#############################################################################\nmodel = SpanEmo(output_dropout=float(args['--output-dropout']),\n                joint_loss=args['--loss-type'],\n                alpha=float(args['--alpha-loss']))\n\n#############################################################################\n# Start Training\n#############################################################################\nlearn = Trainer(model, train_data_loader, dev_data_loader, filename=filename)\nlearn.fit(\n    num_epochs=int(args['--max-epoch']),\n    args=args,\n    device=device\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T01:56:33.846422Z","iopub.execute_input":"2022-12-12T01:56:33.846778Z","iopub.status.idle":"2022-12-12T02:01:34.836936Z","shell.execute_reply.started":"2022-12-12T01:56:33.846747Z","shell.execute_reply":"2022-12-12T02:01:34.834011Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Currently using GPU: cuda:0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff1532a75dc4838a1c8c7e70c795911"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"PreProcessing dataset ...: 100%|██████████| 6838/6838 [00:18<00:00, 365.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"The number of training batches:  214\n","output_type":"stream"},{"name":"stderr","text":"PreProcessing dataset ...: 100%|██████████| 886/886 [00:02<00:00, 375.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"The number of validation batches:  28\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61efb34262884717879c6051eda7acd9"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80c8db2d0c7c4273a8cc2e1421ea0948"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='3' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      15.00% [3/20 04:13<23:58]\n    </div>\n    \n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Train_Loss</th>\n      <th>Val_Loss</th>\n      <th>F1-Macro</th>\n      <th>F1-Micro</th>\n      <th>JS</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0.5138</td>\n      <td>0.4222</td>\n      <td>0.4592</td>\n      <td>0.6522</td>\n      <td>0.5162</td>\n      <td>01:24</td>\n    </tr>\n    <tr>\n      <td>0.4134</td>\n      <td>0.4078</td>\n      <td>0.5182</td>\n      <td>0.6968</td>\n      <td>0.5691</td>\n      <td>01:23</td>\n    </tr>\n    <tr>\n      <td>0.3797</td>\n      <td>0.3948</td>\n      <td>0.5236</td>\n      <td>0.6906</td>\n      <td>0.5638</td>\n      <td>01:23</td>\n    </tr>\n  </tbody>\n</table><p>\n\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='12' class='' max='214' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      5.61% [12/214 00:04<01:15]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"epoch#:  1\nValidation loss decreased (inf --> 0.422159).  Saving model ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"epoch#:  2\nValidation loss decreased (0.422159 --> 0.407821).  Saving model ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"epoch#:  3\nValidation loss decreased (0.407821 --> 0.394753).  Saving model ...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/4185575550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'--max-epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m )\n","\u001b[0;32m/tmp/ipykernel_23/4150098249.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_epochs, args, device)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0moverall_training_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### Test\n\n- Code block to test the model accuracy on test data.\n- Runs the model on the entire test/validation dataset and reports the three metrics.\n- Trained models' file paths are already in the code, uncomment the one to test and comment the rest.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torch\nimport numpy as np\n\nargs={}\n# Base model - SpanEmo paper\nargs['--model-path'] = '/kaggle/working/2022-11-23-14:24:40_checkpoint.pt'\n# Ablation model - with only BCE loss training\n#args['--model-path'] = '/kaggle/working/2022-11-24-22:41:42_checkpoint.pt'\n# Ablation model with only LCA loss training\n#args['--model-path'] = '/kaggle/working/2022-12-07-23:46:25_checkpoint.pt'\n# Model with own LCA loss\n#args['--model-path'] = '/kaggle/working/2022-12-11-03:23:01_checkpoint.pt'\n\n#Ensure same max-length is used as training.\nargs['--max-length'] = int(128)\nargs['--seed'] = int(0) \nargs['--test-batch-size'] = int(16)\nargs['--test-path'] = '/kaggle/input/semeval2018/2018-E-c-En-test-gold.txt'\n\n#args = docopt(__doc__)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nif str(device) == 'cuda:0':\n    print(\"Currently using GPU: {}\".format(device))\n    np.random.seed(int(args['--seed']))\n    torch.cuda.manual_seed_all(int(args['--seed']))\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nelse:\n    print(\"Currently using CPU\")\n\n    \n#####################################################################\n# Define Dataloaders\n#####################################################################\ntest_dataset = DataClass(args, args['--test-path'])\ntest_data_loader = DataLoader(test_dataset,\n                              batch_size=int(args['--test-batch-size']),\n                              shuffle=False)\nprint('The number of Test batches: ', len(test_data_loader))\n\n        \n#############################################################################\n# Run the model on a Test set\n#############################################################################\nmodel = SpanEmo()\nlearn = EvaluateOnTest(model, test_data_loader, model_path=args['--model-path'])\nlearn.predict(device=device)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T02:03:27.586303Z","iopub.execute_input":"2022-12-12T02:03:27.587015Z","iopub.status.idle":"2022-12-12T02:03:52.593811Z","shell.execute_reply.started":"2022-12-12T02:03:27.586981Z","shell.execute_reply":"2022-12-12T02:03:52.592773Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Currently using GPU: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"PreProcessing dataset ...: 100%|██████████| 3259/3259 [00:08<00:00, 384.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"The number of Test batches:  204\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"F1-Macro: 0.5724 F1-Micro: 0.7107 JS: 0.5938 Time: 00:13\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]}]}