{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CS6120 Final Project: Group-14: Label-Correlation Aware Emotion Classification\n- In this project we studied the importance of using label-correlation idea in the task of emotion classification using tweets from SemEval dataset.\n- We perform the following tasks for this project:\n    - clean and preprocess the data,\n    - do some exploroatory analysis on the dataset,\n    - prepare and train the model with various loss functions,\n    - do ablation experiments with loss functions,\n    - and draw observations from the results.","metadata":{}},{"cell_type":"markdown","source":"### Environment setup\n\nBefore beginning the experiments, we do the required environment setup by installing all the required packages for the project","metadata":{}},{"cell_type":"code","source":"# package installs\n!pip install numpy\n!pip install sklearn\n!pip install fastprogress==0.2.3\n!pip install docopt==0.6.2\n!pip install transformers==3.0.2\n!pip install pandas==0.24.2\n!pip install ekphrasis\n!pip install tqdm==4.31.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset exploration\nIn this section, we do the following analysis on the dataset:\n- Identify the emotion distribution across the dataset (train, validation, and test splits.)\n- Identify the label correlation among train and validaiton splits.","metadata":{}},{"cell_type":"code","source":"# Dataset exploration\n# imports\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\n# Change the filenames accordingly to use the train validaiton and test files respectively\ntrain_filename = '/kaggle/input/semeval2018/2018-E-c-En-train/2018-E-c-En-train.txt'\nval_filename = '/kaggle/input/semeval2018/2018-E-c-En-dev/2018-E-c-En-dev.txt'\ntest_filename = '/kaggle/input/semeval2018/2018-E-c-En-test-gold.txt'\n\n# Read the data from the files to appropriate data frames.\ntrain_df = pd.read_csv(train_filename, sep='\\t')\nx_train, y_train = train_df.Tweet.values, train_df.iloc[:, 2:].values\n\nval_df = pd.read_csv(val_filename, sep='\\t')\nx_val, y_val = val_df.Tweet.values, val_df.iloc[:, 2:].values\n\ntest_df = pd.read_csv(test_filename, sep='\\t')\nx_test, y_test = test_df.Tweet.values, test_df.iloc[:, 2:].values\n\n# Concatenate all the label data\ny_cat = np.concatenate((y_train, y_val, y_test), axis=0)\n\n# count the number of emotions in each tweet. 0-neutral, 1-single emotion, 2-2 emotions ...\ncounts = np.zeros((11)) # 11 emotions possible at max\nfor y in y_cat:\n    num_emotions = np.count_nonzero(y)\n    counts[num_emotions]+=1\n\n# Original counts as is.\nprint(\"Emotion distribution counts:\", counts)\n\n# Percentage counts\nprint(\"Emotion distribution percentages:\", counts/109.83)\n\n# Label correlation on validation set labels.\ny_val_df = val_df.iloc[:, 2:]\ncorr_df = y_val_df.corr(method='kendall')\nsns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.heatmap(corr_df, annot=False)\n\n# Label correlation on the train set labels to be used for the Label Correlation Loss in later sections of the code.\ny_train_df = train_df.iloc[:, 2:]\nlabel_graph = train_df.corr(method='kendall')\nlabel_graph = label_graph.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T14:31:39.318655Z","iopub.execute_input":"2022-12-11T14:31:39.319098Z","iopub.status.idle":"2022-12-11T14:31:39.911812Z","shell.execute_reply.started":"2022-12-11T14:31:39.319061Z","shell.execute_reply":"2022-12-11T14:31:39.910773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Twitter data preprocessor from the paper: **\"Deep lstm with attention for message-level and topic-based sentiment analysis.\"**","metadata":{}},{"cell_type":"code","source":"# imports\nfrom torch.utils.data import Dataset\nfrom transformers import BertTokenizer, AutoTokenizer\nfrom tqdm import tqdm\nimport torch\nimport pandas as pd\nfrom ekphrasis.classes.tokenizer import SocialTokenizer\nfrom ekphrasis.classes.preprocessor import TextPreProcessor\n\ndef twitter_preprocessor():\n    \"\"\" preprocess the tweets according to the paper: Deep lstm with attention for message-level and \n    topic-based sentiment analysis.\n    Normalizes URLs, usernames, contact info in the tweets,\n    tokenizes the data\n    \"\"\"\n    preprocessor = TextPreProcessor(\n        normalize=['url', 'email', 'phone', 'user'],\n        annotate={\"hashtag\", \"elongated\", \"allcaps\", \"repeated\", 'emphasis', 'censored'},\n        all_caps_tag=\"wrap\",\n        fix_text=False,\n        segmenter=\"twitter_2018\",\n        corrector=\"twitter_2018\",\n        unpack_hashtags=True,\n        unpack_contractions=True,\n        spell_correct_elong=False,\n        tokenizer=SocialTokenizer(lowercase=True).tokenize).pre_process_doc\n    return preprocessor\n\n# Create a preprocess object and keep it ready for use in the dataset class\npreprocessor = twitter_preprocessor()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T02:37:35.373746Z","iopub.execute_input":"2022-12-11T02:37:35.374102Z","iopub.status.idle":"2022-12-11T02:38:14.050219Z","shell.execute_reply.started":"2022-12-11T02:37:35.374073Z","shell.execute_reply":"2022-12-11T02:38:14.049092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset class to train and evaluate the model.\n- Reads data from files and preprocess the tweets to tokens\n- Runs the tokens through BERT tokenizer to generate IDs for each token and returns a batch of this data.","metadata":{}},{"cell_type":"code","source":"# Dataset class that reads tweets and labels from the files and prepares batches of data for training, test.\nclass DataClass(Dataset):\n    def __init__(self, args, filename):\n        self.args = args\n        self.filename = filename\n        self.max_length = int(args['--max-length'])\n        self.data, self.labels = self.load_dataset()\n        \n        self.bert_tokeniser = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n        self.inputs, self.lengths, self.label_indices = self.process_data()\n\n    def load_dataset(self):\n        \"\"\"\n        :return: dataset after being preprocessed and tokenised\n        \"\"\"\n        df = pd.read_csv(self.filename, sep='\\t')\n        x_train, y_train = df.Tweet.values, df.iloc[:, 2:].values\n        return x_train, y_train\n\n    def process_data(self):\n        desc = \"PreProcessing dataset {}...\".format('')\n        \n        segment_a = \"anger anticipation disgust fear joy love optimism hopeless sadness surprise or trust?\"\n        label_names = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\",\n                       \"love\", \"optimism\", \"hopeless\", \"sadness\", \"surprise\", \"trust\"]\n\n        inputs, lengths, label_indices = [], [], []\n        for x in tqdm(self.data, desc=desc):\n            x = ' '.join(preprocessor(x))\n            x = self.bert_tokeniser.encode_plus(segment_a,\n                                                x,\n                                                add_special_tokens=True,\n                                                max_length=self.max_length,\n                                                pad_to_max_length=True,\n                                                truncation=True)\n            input_id = x['input_ids']\n            input_length = len([i for i in x['attention_mask'] if i == 1])\n            inputs.append(input_id)\n            lengths.append(input_length)\n\n            #label indices\n            label_idxs = [self.bert_tokeniser.convert_ids_to_tokens(input_id).index(label_names[idx])\n                             for idx, _ in enumerate(label_names)]\n            label_indices.append(label_idxs)\n\n        inputs = torch.tensor(inputs, dtype=torch.long)\n        data_length = torch.tensor(lengths, dtype=torch.long)\n        label_indices = torch.tensor(label_indices, dtype=torch.long)\n        return inputs, data_length, label_indices\n\n    def __getitem__(self, index):\n        inputs = self.inputs[index]\n        labels = self.labels[index]\n        label_idxs = self.label_indices[index]\n        length = self.lengths[index]\n        return inputs, labels, length, label_idxs\n\n    def __len__(self):\n        return len(self.inputs)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T02:38:24.644434Z","iopub.execute_input":"2022-12-11T02:38:24.645438Z","iopub.status.idle":"2022-12-11T02:38:24.715831Z","shell.execute_reply.started":"2022-12-11T02:38:24.645400Z","shell.execute_reply":"2022-12-11T02:38:24.714707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Installing the exact version of transformer is crucial for the model to run.","metadata":{}},{"cell_type":"code","source":"# package installation for the transformer model\n!pip install transformers==3.0.2","metadata":{"execution":{"iopub.status.busy":"2022-12-11T02:38:28.613252Z","iopub.execute_input":"2022-12-11T02:38:28.613630Z","iopub.status.idle":"2022-12-11T02:38:37.941705Z","shell.execute_reply.started":"2022-12-11T02:38:28.613599Z","shell.execute_reply":"2022-12-11T02:38:37.940537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SpanEmo model.\n- Contains BERT encoder as the first part of the network. \n- Features from BERT are passed through a feed forward network to generate class probabilities for each class.\n- For the label correlation aware loss (joint2), we use the label graph (label-correlation data from the train split) as attention to generate a better mapping in the soft BCE loss.\n- See paper: **'Review-Driven Multi-Label Music Style Classification by Exploiting Style Correlations'** for more details on the LCA loss used in 'joint2' loss function.","metadata":{}},{"cell_type":"code","source":"#from transformers.modeling_bert import BertModel\nfrom transformers import BertModel #, AutoModel\n#from transformers.models.bert.modeling_bert import BertModel\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\nimport transformers \n\n\nclass BertEncoder(nn.Module):\n    def __init__(self):\n        super(BertEncoder, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.feature_size = self.bert.config.hidden_size\n\n    def forward(self, input_ids):\n        \"\"\"\n        :param input_ids: list[str], list of tokenised sentences\n        :return: last hidden representation, torch.tensor of shape (batch_size, seq_length, hidden_dim)\n        \"\"\"\n        if int((transformers.__version__)[0]) == 4:\n            last_hidden_state = self.bert(input_ids=input_ids).last_hidden_state\n        else: #transformers version should be as indicated in the requirements.txt file\n            last_hidden_state, pooler_output = self.bert(input_ids=input_ids)\n        return last_hidden_state\n\n\nclass SpanEmo(nn.Module):\n    def __init__(self, output_dropout=0.1, joint_loss='joint', alpha=0.2):\n        \"\"\" casting multi-label emotion classification as span-extraction\n        :param output_dropout: The dropout probability for output layer\n        :param joint_loss: which loss to use cel|corr|cel+corr\n        :param alpha: control contribution of each loss function in case of joint training\n        \"\"\"\n        super(SpanEmo, self).__init__()\n        self.bert = BertEncoder()\n        self.joint_loss = joint_loss\n        self.alpha = alpha\n        \n        self.ffn = nn.Sequential(\n            nn.Linear(self.bert.feature_size, self.bert.feature_size),\n            nn.Tanh(),\n            nn.Dropout(p=output_dropout),\n            nn.Linear(self.bert.feature_size, 1)\n        )\n        \n        # temperature parameter for the soft BCE loss to be used in LCA loss (joint2).\n        self.temp = 5.0\n\n        #Label correlation matrix as a parameter. \n        #See eq 5 in paper: Review-Driven Multi-Label Music Style Classification by Exploiting Style Correlations\n        self.label_corr = torch.nn.Linear(11, 11, bias=False)\n        # Initializing the label graph layer with correlation matrix from train data.\n        with torch.no_grad():\n            self.label_corr.weight.copy_(torch.tensor(label_graph, dtype=torch.float))\n\n    def forward(self, batch, device):\n        \"\"\"\n        :param batch: tuple of (input_ids, labels, length, label_indices)\n        :param device: device to run calculations on\n        :return: loss, num_rows, y_pred, targets\n        \"\"\"\n        #prepare inputs and targets\n        inputs, targets, lengths, label_idxs = batch\n        inputs, num_rows = inputs.to(device), inputs.size(0)\n        label_idxs, targets = label_idxs[0].long().to(device), targets.float().to(device)\n\n        #Bert encoder\n        last_hidden_state = self.bert(inputs)\n\n        # FFN---> 2 linear layers---> linear layer + tanh---> linear layer\n        # select span of labels to compare them with ground truth ones\n        logits = self.ffn(last_hidden_state).squeeze(-1).index_select(dim=1, index=label_idxs)\n\n        #Loss Function\n        if self.joint_loss == 'joint':\n            cel = F.binary_cross_entropy_with_logits(logits, targets).cuda()\n            cl = self.corr_loss(logits, targets)\n            loss = ((1 - self.alpha) * cel) + (self.alpha * cl)\n        elif self.joint_loss == 'cross-entropy':\n            loss = F.binary_cross_entropy_with_logits(logits, targets).cuda()\n        elif self.joint_loss == 'corr_loss':\n            loss = self.corr_loss(logits, targets)\n        # New loss function using label graph training parameter and BCE loss with temperature.\n        elif self.joint_loss == 'joint2':\n            cel = F.binary_cross_entropy_with_logits(logits, targets).cuda()\n            cl = self.lca_loss(logits, targets)\n            loss = ((1 - self.alpha) * cel) + (self.alpha * cl)\n\n        y_pred = self.compute_pred(logits)\n        return loss, num_rows, y_pred, targets.cpu().numpy()\n\n    def lca_loss(self, y_hat, y_true):\n        \"\"\" LCA loss that uses the graph_labels to weight the label correlation.\n        :param y_hat: output raw probabilities from the model.\n        :param y_true: target labels.\n        :return lca loss\n        \"\"\"\n        #y_hat_dash = torch.matmul(y_hat.sigmoid(), self.label_corr)\n        # Matrix multiplication between the label graph and the outputs from the model.\n        y_hat_dash = self.label_corr(y_hat.sigmoid())\n        \n        # Softmax dimension based on the label_corr position in the matrix multiplication.\n        label_corr_soft = F.softmax(self.label_corr.weight/self.temp, dim=0)\n        y_true_dash = torch.matmul(y_true, label_corr_soft)\n\n        return F.binary_cross_entropy_with_logits(y_hat_dash, y_true_dash).cuda()\n    \n    @staticmethod\n    def corr_loss(y_hat, y_true, reduction='mean'):\n        \"\"\"\n        :param y_hat: model predictions, shape(batch, classes)\n        :param y_true: target labels (batch, classes)\n        :param reduction: whether to avg or sum loss\n        :return: loss\n        \"\"\"\n        loss = torch.zeros(y_true.size(0)).cuda()\n        for idx, (y, y_h) in enumerate(zip(y_true, y_hat.sigmoid())):\n            y_z, y_o = (y == 0).nonzero(), y.nonzero()\n            if y_o.nelement() != 0:\n                output = torch.exp(torch.sub(y_h[y_z], y_h[y_o][:, None]).squeeze(-1)).sum()\n                num_comparisons = y_z.size(0) * y_o.size(0)\n                loss[idx] = output.div(num_comparisons)\n        return loss.mean() if reduction == 'mean' else loss.sum()\n        \n    @staticmethod\n    def compute_pred(logits, threshold=0.5):\n        \"\"\"\n        :param logits: model predictions\n        :param threshold: threshold value\n        :return:\n        \"\"\"\n        y_pred = torch.sigmoid(logits) > threshold\n        return y_pred.float().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T03:22:59.448800Z","iopub.execute_input":"2022-12-11T03:22:59.449205Z","iopub.status.idle":"2022-12-11T03:22:59.480273Z","shell.execute_reply.started":"2022-12-11T03:22:59.449173Z","shell.execute_reply":"2022-12-11T03:22:59.479189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and Testing utils\n\nNext, we define trainer, early stopper classes to help run the training, validation, and early stopping if the validation loss doesn't go down after a set number of epochs.\n- EarlyStopper:\n    - Checks if the validation loss is less than previous epoch, if yes saves the checkpoint if not, increments the early stop counter.\n    - When the early stop counter reaches 10, the training is terminated.\n- Trainer:\n    - Creates an optimizer with different learning rates for BERT, FFN, and the label graph parameters to optimize them.\n    - Optimize the model by running back propogation on the combined loss function.\n    - Predict emotions from a given tweet and return the logits.\n- Evaluate:\n    - Runs the model on the entire test/validation data and generates F1-micro/macro, jaccard score metrics.","metadata":{}},{"cell_type":"code","source":"from fastprogress.fastprogress import format_time, master_bar, progress_bar\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import f1_score, jaccard_score\nimport torch.nn.functional as F\nimport numpy as np\nimport torch\nimport time\n\n\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\n    Taken from https://github.com/Bjarten/early-stopping-pytorch\"\"\"\n\n    def __init__(self, filename, patience=7, verbose=True, delta=0):\n        \"\"\"\n        :param patience: How long to wait after last time validation loss improved.\n        :param verbose: If True, prints a message for each validation loss improvement.\n        :param delta: Minimum change in the monitored quantity to qualify as an improvement.\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.cur_date = filename\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decreases.\"\"\"\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), '/kaggle/working/' + self.cur_date + '_checkpoint.pt')\n        self.val_loss_min = val_loss\n\n\nclass Trainer(object):\n    \"\"\"\n    Class to encapsulate training and validation steps for a pipeline. Based off the \"Tonks Library\"\n    :param model: PyTorch model to use with the Learner\n    :param train_data_loader: dataloader for all of the training data\n    :param val_data_loader: dataloader for all of the validation data\n    :param filename: the best model will be saved using this given name (str)\n    \"\"\"\n\n    def __init__(self, model, train_data_loader, val_data_loader, filename):\n        self.model = model\n        self.train_data_loader = train_data_loader\n        self.val_data_loader = val_data_loader\n        self.filename = filename\n        self.early_stop = EarlyStopping(self.filename, patience=10)\n\n    def fit(self, num_epochs, args, device='cuda:0'):\n        \"\"\"\n        Fit the PyTorch model\n        :param num_epochs: number of epochs to train (int)\n        :param args:\n        :param device: str (defaults to 'cuda:0')\n        \"\"\"\n        optimizer, scheduler, step_scheduler_on_batch = self.optimizer(args)\n        self.model = self.model.to(device)\n        pbar = master_bar(range(num_epochs))\n        headers = ['Train_Loss', 'Val_Loss', 'F1-Macro', 'F1-Micro', 'JS', 'Time']\n        pbar.write(headers, table=True)\n        for epoch in pbar:\n            epoch += 1\n            start_time = time.time()\n            self.model.train()\n            overall_training_loss = 0.0\n            for step, batch in enumerate(progress_bar(self.train_data_loader, parent=pbar)):\n                loss, num_rows, _, _ = self.model(batch, device)\n                overall_training_loss += loss.item() * num_rows\n\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                optimizer.step()\n                if step_scheduler_on_batch:\n                    scheduler.step()\n                optimizer.zero_grad()\n\n            if not step_scheduler_on_batch:\n                scheduler.step()\n\n            overall_training_loss = overall_training_loss / len(self.train_data_loader.dataset)\n            overall_val_loss, pred_dict = self.predict(device, pbar)\n            y_true, y_pred = pred_dict['y_true'], pred_dict['y_pred']\n\n            str_stats = []\n            stats = [overall_training_loss,\n                     overall_val_loss,\n                     f1_score(y_true, y_pred, average=\"macro\"),\n                     f1_score(y_true, y_pred, average=\"micro\"),\n                     jaccard_score(y_true, y_pred, average=\"samples\")]\n\n            for stat in stats:\n                str_stats.append(\n                    'NA' if stat is None else str(stat) if isinstance(stat, int) else f'{stat:.4f}'\n                )\n            str_stats.append(format_time(time.time() - start_time))\n            print('epoch#: ', epoch)\n            pbar.write(str_stats, table=True)\n            self.early_stop(overall_val_loss, self.model)\n            if self.early_stop.early_stop:\n                print(\"Early stopping\")\n                break\n                \n    def optimizer(self, args):\n        \"\"\"\n        :param args: object\n        \"\"\"\n        optimizer = AdamW([\n            {'params': self.model.bert.parameters()},\n            {'params': self.model.label_corr.parameters()},\n            {'params': self.model.ffn.parameters(),\n             'lr': float(args['--ffn-lr'])},\n        ], lr=float(args['--bert-lr']), correct_bias=True)\n        num_train_steps = (int(len(self.train_data_loader.dataset)) /\n                           int(args['--train-batch-size'])) * int(args['--max-epoch'])\n        num_warmup_steps = int(num_train_steps * 0.1)\n        scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                    num_warmup_steps=num_warmup_steps,\n                                                    num_training_steps=num_train_steps)\n        step_scheduler_on_batch = True\n        return optimizer, scheduler, step_scheduler_on_batch\n\n    def predict(self, device='cuda:0', pbar=None):\n        \"\"\"\n        Evaluate the model on a validation set\n        :param device: str (defaults to 'cuda:0')\n        :param pbar: fast_progress progress bar (defaults to None)\n        :returns: overall_val_loss (float), accuracies (dict{'acc': value}, preds (dict)\n        \"\"\"\n        current_size = len(self.val_data_loader.dataset)\n        preds_dict = {\n            'y_true': np.zeros([current_size, 11]),\n            'y_pred': np.zeros([current_size, 11])\n        }\n        overall_val_loss = 0.0\n        self.model.eval()\n        with torch.no_grad():\n            index_dict = 0\n            for step, batch in enumerate(progress_bar(self.val_data_loader, parent=pbar, leave=(pbar is not None))):\n                loss, num_rows, y_pred, targets = self.model(batch, device)\n                overall_val_loss += loss.item() * num_rows\n\n                current_index = index_dict\n                preds_dict['y_true'][current_index: current_index + num_rows, :] = targets\n                preds_dict['y_pred'][current_index: current_index + num_rows, :] = y_pred\n                index_dict += num_rows\n\n        overall_val_loss = overall_val_loss / len(self.val_data_loader.dataset)\n        return overall_val_loss, preds_dict\n\nclass EvaluateOnTest(object):\n    \"\"\"\n    Class to encapsulate evaluation on the test set. Based off the \"Tonks Library\"\n    :param model: PyTorch model to use with the Learner\n    :param test_data_loader: dataloader for all of the validation data\n    :param model_path: path of the trained model\n    \"\"\"\n    def __init__(self, model, test_data_loader, model_path):\n        self.model = model\n        self.test_data_loader = test_data_loader\n        self.model_path = model_path\n\n    def predict(self, device='cuda:0', pbar=None):\n        \"\"\"\n        Evaluate the model on a validation set\n        :param device: str (defaults to 'cuda:0')\n        :param pbar: fast_progress progress bar (defaults to None)\n        :returns: None\n        \"\"\"\n        self.model.to(device).load_state_dict(torch.load(self.model_path))\n        self.model.eval()\n        current_size = len(self.test_data_loader.dataset)\n        preds_dict = {\n            'y_true': np.zeros([current_size, 11]),\n            'y_pred': np.zeros([current_size, 11])\n        }\n        start_time = time.time()\n        with torch.no_grad():\n            index_dict = 0\n            for step, batch in enumerate(progress_bar(self.test_data_loader, parent=pbar, leave=(pbar is not None))):\n                _, num_rows, y_pred, targets = self.model(batch, device)\n                current_index = index_dict\n                preds_dict['y_true'][current_index: current_index + num_rows, :] = targets\n                preds_dict['y_pred'][current_index: current_index + num_rows, :] = y_pred\n                index_dict += num_rows\n\n        y_true, y_pred = preds_dict['y_true'], preds_dict['y_pred']\n        str_stats = []\n        stats = [f1_score(y_true, y_pred, average=\"macro\"),\n                 f1_score(y_true, y_pred, average=\"micro\"),\n                 jaccard_score(y_true, y_pred, average=\"samples\")]\n\n        for stat in stats:\n            str_stats.append(\n                'NA' if stat is None else str(stat) if isinstance(stat, int) else f'{stat:.4f}'\n            )\n        str_stats.append(format_time(time.time() - start_time))\n        headers = ['F1-Macro', 'F1-Micro', 'JS', 'Time']\n        print(' '.join('{}: {}'.format(*k) for k in zip(headers, str_stats)))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T03:23:00.346392Z","iopub.execute_input":"2022-12-11T03:23:00.346795Z","iopub.status.idle":"2022-12-11T03:23:00.385683Z","shell.execute_reply.started":"2022-12-11T03:23:00.346762Z","shell.execute_reply":"2022-12-11T03:23:00.384589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train\n- Main code block that sets the parameters for training. Calls the trainer object to run the training.\n- Checkpoints are saved in the 'kaggle/working/' directory based on the time and date of the experiment.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nOptions:\n    --loss-type=<str>                 Which loss to use cross-entropy|corr_loss|joint. [default: joint]\n    --max-length=<int>                text length [default: 128]\n    --output-dropout=<float>          prob of dropout applied to the output layer [default: 0.1]\n    --seed=<int>                      fixed random seed number [default: 42]\n    --train-batch-size=<int>          batch size [default: 32]\n    --eval-batch-size=<int>           batch size [default: 32]\n    --max-epoch=<int>                 max epoch [default: 20]\n    --ffn-lr=<float>                  ffn learning rate [default: 0.001]\n    --bert-lr=<float>                 bert learning rate [default: 2e-5]\n    --dev-path=<str>                  file path of the dev set [default: '/semeval2018/2018-E-c-En-dev/2018-E-c-En-dev.txt']\n    --train-path=<str>                file path of the train set [default: '/semeval2018/2018-E-c-En-train/2018-E-c-En-train.txt']\n    --alpha-loss=<float>              weight used to balance the loss [default: 0.2]\n\"\"\"\n\nfrom torch.utils.data import DataLoader\nimport torch\nimport datetime\nimport json\nimport numpy as np\n\n# making arg parser as a dictionary to run in a notebook.\nargs = {}\nargs['--loss-type'] = 'joint2' #'joint' #'corr_loss' #'cross-entropy' #'joint'\nargs['--max-length'] = int(128)\nargs['--output-dropout'] = 0.1\nargs['--seed'] = 42\nargs['--train-batch-size'] = int(32)\nargs['--eval-batch-size'] = int(32)\nargs['--max-epoch'] = int(20)\nargs['--ffn-lr'] = 0.001\nargs['--bert-lr'] = 2e-5\nargs['--dev-path'] = '../input/semeval2018/2018-E-c-En-dev/2018-E-c-En-dev.txt'\nargs['--train-path'] = '../input/semeval2018/2018-E-c-En-train/2018-E-c-En-train.txt'\nargs['--alpha-loss'] = 0.2\n\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nif str(device) == 'cuda:0':\n    print(\"Currently using GPU: {}\".format(device))\n    np.random.seed(int(args['--seed']))\n    torch.cuda.manual_seed_all(int(args['--seed']))\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nelse:\n    print(\"Currently using CPU\")\n\n#####################################################################\n# Save hyper-parameter values ---> config.json\n# Save model weights ---> filename.pt using current time\n#####################################################################\nnow = datetime.datetime.now()\nfilename = now.strftime(\"%Y-%m-%d-%H:%M:%S\")\nfw = open('/kaggle/working/' + filename + '.json', 'a')\nmodel_path = '/kaggle/working/'+ filename + '.pt'\nargs['--checkpoint-path'] = model_path\njson.dump(args, fw, sort_keys=True, indent=2)\n\n#####################################################################\n# Define Dataloaders\n#####################################################################\ntrain_dataset = DataClass(args, args['--train-path'])\ntrain_data_loader = DataLoader(train_dataset,\n                               batch_size=int(args['--train-batch-size']),\n                               shuffle=True\n                               )\nprint('The number of training batches: ', len(train_data_loader))\ndev_dataset = DataClass(args, args['--dev-path'])\ndev_data_loader = DataLoader(dev_dataset,\n                             batch_size=int(args['--eval-batch-size']),\n                             shuffle=False\n                             )\nprint('The number of validation batches: ', len(dev_data_loader))\n\n#############################################################################\n# Define Model & Training Pipeline\n#############################################################################\nmodel = SpanEmo(output_dropout=float(args['--output-dropout']),\n                joint_loss=args['--loss-type'],\n                alpha=float(args['--alpha-loss']))\n\n#############################################################################\n# Start Training\n#############################################################################\nlearn = Trainer(model, train_data_loader, dev_data_loader, filename=filename)\nlearn.fit(\n    num_epochs=int(args['--max-epoch']),\n    args=args,\n    device=device\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T03:23:01.020052Z","iopub.execute_input":"2022-12-11T03:23:01.020835Z","iopub.status.idle":"2022-12-11T03:36:56.816923Z","shell.execute_reply.started":"2022-12-11T03:23:01.020791Z","shell.execute_reply":"2022-12-11T03:36:56.815712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test\n\n- Code block to test the model accuracy on test data.\n- Runs the model on the entire test/validation dataset and reports the three metrics.\n- Trained models' file paths are already in the code, uncomment the one to test and comment the rest.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torch\nimport numpy as np\n\nargs={}\n# Base model - SpanEmo paper\n#args['--model-path'] = '/kaggle/working/2022-11-23-14:24:40_checkpoint.pt'\n# Ablation model - with only BCE loss training\n#args['--model-path'] = '/kaggle/working/2022-11-24-22:41:42_checkpoint.pt'\n# Ablation model with only LCA loss training\n#args['--model-path'] = '/kaggle/working/2022-12-07-23:46:25_checkpoint.pt'\n# Model with own LCA loss\nargs['--model-path'] = '/kaggle/working/2022-12-11-03:23:01_checkpoint.pt'\n\n#Ensure same max-length is used as training.\nargs['--max-length'] = int(128)\nargs['--seed'] = int(0) \nargs['--test-batch-size'] = int(16)\nargs['--test-path'] = '/kaggle/input/semeval2018/2018-E-c-En-test-gold.txt'\n\n#args = docopt(__doc__)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nif str(device) == 'cuda:0':\n    print(\"Currently using GPU: {}\".format(device))\n    np.random.seed(int(args['--seed']))\n    torch.cuda.manual_seed_all(int(args['--seed']))\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nelse:\n    print(\"Currently using CPU\")\n\n    \n#####################################################################\n# Define Dataloaders\n#####################################################################\ntest_dataset = DataClass(args, args['--test-path'])\ntest_data_loader = DataLoader(test_dataset,\n                              batch_size=int(args['--test-batch-size']),\n                              shuffle=False)\nprint('The number of Test batches: ', len(test_data_loader))\n\n        \n#############################################################################\n# Run the model on a Test set\n#############################################################################\nmodel = SpanEmo()\nlearn = EvaluateOnTest(model, test_data_loader, model_path=args['--model-path'])\nlearn.predict(device=device)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T03:41:25.589951Z","iopub.execute_input":"2022-12-11T03:41:25.590369Z","iopub.status.idle":"2022-12-11T03:41:50.017926Z","shell.execute_reply.started":"2022-12-11T03:41:25.590336Z","shell.execute_reply":"2022-12-11T03:41:50.016917Z"},"trusted":true},"execution_count":null,"outputs":[]}]}